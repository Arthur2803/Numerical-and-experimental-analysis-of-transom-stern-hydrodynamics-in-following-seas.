{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b56d6dc2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calibration data file not found. Performing calibration using video: \\\\sambaad.stud.ntnu.no\\arthursl\\.profil\\stud\\datasal\\Desktop\\Master\\Master\\Code\\PostProcess\\Resultater\\Sjakkbrett_cali1.avi\n",
      "Processing calibration video frames...\n",
      "Saved \\\\sambaad.stud.ntnu.no\\arthursl\\.profil\\stud\\datasal\\Desktop\\Master\\Master\\Code\\PostProcess\\debug_calibration_frame_001.png for inspection.\n",
      "Saved \\\\sambaad.stud.ntnu.no\\arthursl\\.profil\\stud\\datasal\\Desktop\\Master\\Master\\Code\\PostProcess\\debug_calibration_frame_002.png for inspection.\n",
      "Saved \\\\sambaad.stud.ntnu.no\\arthursl\\.profil\\stud\\datasal\\Desktop\\Master\\Master\\Code\\PostProcess\\debug_calibration_frame_003.png for inspection.\n",
      "Saved \\\\sambaad.stud.ntnu.no\\arthursl\\.profil\\stud\\datasal\\Desktop\\Master\\Master\\Code\\PostProcess\\debug_calibration_frame_004.png for inspection.\n",
      "Saved \\\\sambaad.stud.ntnu.no\\arthursl\\.profil\\stud\\datasal\\Desktop\\Master\\Master\\Code\\PostProcess\\debug_calibration_frame_005.png for inspection.\n",
      "Found corners in frame 9, total frames with corners: 1\n",
      "Found corners in frame 10, total frames with corners: 2\n",
      "Found corners in frame 11, total frames with corners: 3\n",
      "Found corners in frame 12, total frames with corners: 4\n",
      "Found corners in frame 13, total frames with corners: 5\n",
      "Found corners in frame 14, total frames with corners: 6\n",
      "Found corners in frame 15, total frames with corners: 7\n",
      "Found corners in frame 17, total frames with corners: 8\n",
      "Processed 20 frames, corners not found in current frame.\n",
      "Found corners in frame 21, total frames with corners: 9\n",
      "Found corners in frame 22, total frames with corners: 10\n",
      "Found corners in frame 23, total frames with corners: 11\n",
      "Processed 30 frames, corners not found in current frame.\n",
      "Processed 40 frames, corners not found in current frame.\n",
      "Processed 50 frames, corners not found in current frame.\n",
      "\n",
      "Performing camera calibration with 11 images...\n",
      "RMS re-projection error from calibrateCamera: 0.1214\n",
      "Camera calibrated successfully. RMS re-projection error: 0.1214\n",
      "Mean re-projection error (calculated manually per image): 0.01723499715273231\n",
      "\n",
      "--- Manual Frame Selection for mm_per_pixel Calculation ---\n",
      "Press 's' to select the current frame for mm/pixel calculation.\n",
      "Press 'n' or SPACE to view the next frame.\n",
      "Press 'q' to quit selection without calculating mm/pixel.\n"
     ]
    }
   ],
   "source": [
    "#CALINRATION CODE\n",
    "\n",
    "\n",
    "import cv2\n",
    "import numpy as np\n",
    "import os\n",
    "import glob # For finding calibration images if used instead of video\n",
    "\n",
    "\n",
    "CHESSBOARD_CORNERS_ROWCOL = (7, 7) # Detect a 7x7 pattern\n",
    "CHESSBOARD_SQUARE_SIZE_MM = 20.0  # Size of a chessboard square in millimeters\n",
    "\n",
    "\n",
    "FULL_BOARD_INNER_CORNERS_ROWCOL = (20, 20) # Assuming a 21x21 square physical board\n",
    "\n",
    "\n",
    "POSTPROCESS_BASE_DIR = r\"\\\\sambaad.stud.ntnu.no\\arthursl\\.profil\\stud\\datasal\\Desktop\\Master\\Master\\Code\\PostProcess\"\n",
    "os.makedirs(POSTPROCESS_BASE_DIR, exist_ok=True) # Ensure the directory exists\n",
    "\n",
    "calibration_path = r\"\\\\sambaad.stud.ntnu.no\\arthursl\\.profil\\stud\\datasal\\Desktop\\Master\\Master\\Code\\PostProcess\\Resultater\\Sjakkbrett_cali1.avi\"\n",
    "# File to save/load camera calibration data (camera matrix, distortion coefficients, mm_per_pixel).\n",
    "calibration_data_file = os.path.join(POSTPROCESS_BASE_DIR, \"calibration_data_4.npz\")\n",
    "\n",
    "\n",
    "offset_x = FULL_BOARD_INNER_CORNERS_ROWCOL[0] - CHESSBOARD_CORNERS_ROWCOL[0]\n",
    "\n",
    "# offset_y: The starting row index for the top-right 7x7 section.\n",
    "# This is 0, as it's the \"top\" row.\n",
    "offset_y = 0\n",
    "offset = np.array([offset_x, offset_y], dtype=np.float32)\n",
    "\n",
    "# objp now represents the 3D coordinates of the sub-pattern's corners\n",
    "# relative to the full chessboard's origin (e.g., its top-left inner corner).\n",
    "objp = np.zeros((CHESSBOARD_CORNERS_ROWCOL[0] * CHESSBOARD_CORNERS_ROWCOL[1], 3), np.float32)\n",
    "# Create a grid for the sub-pattern (from 0,0 to CHESSBOARD_CORNERS_ROWCOL-1)\n",
    "sub_pattern_grid = np.mgrid[0:CHESSBOARD_CORNERS_ROWCOL[0], 0:CHESSBOARD_CORNERS_ROWCOL[1]].T.reshape(-1,2)\n",
    "#sub_pattern_grid = np.mgrid[0:CHESSBOARD_CORNERS_ROWCOL[0], 0:CHESSBOARD_CORNERS_ROWCOL[1]].T.reshape(-1,3)\n",
    "#sub_pattern_grid = np.mgrid[0:CHESSBOARD_CORNERS_ROWCOL[0], 0:CHESSBOARD_CORNERS_ROWCOL[1]].T.reshape(-1,4)\n",
    "#sub_pattern_grid = np.mgrid[0:CHESSBOARD_CORNERS_ROWCOL[0], 0:CHESSBOARD_CORNERS_ROWCOL[1]].T.reshape(-1,5)\n",
    "# Apply the offset and scale to real-world coordinates\n",
    "objp[:,:2] = (sub_pattern_grid + offset) * CHESSBOARD_SQUARE_SIZE_MM\n",
    "\n",
    ".\n",
    "objpoints = [] \n",
    "imgpoints = [] \n",
    "\n",
    "\n",
    "mtx, dist, mm_per_pixel = None, None, None\n",
    "\n",
    "if os.path.exists(calibration_data_file):\n",
    "    print(f\"Loading calibration data from {calibration_data_file}\")\n",
    "    data = np.load(calibration_data_file, allow_pickle=True) # Added allow_pickle=True\n",
    "    mtx = data['mtx']\n",
    "    dist = data['dist']\n",
    "    if 'mm_per_pixel' in data:\n",
    "        mm_per_pixel = data['mm_per_pixel']\n",
    "    else:\n",
    "        print(\"mm_per_pixel not found in calibration data, will attempt to calculate.\")\n",
    "else:\n",
    "    print(f\"Calibration data file not found. Performing calibration using video: {calibration_path}\")\n",
    "    cap_cal = cv2.VideoCapture(calibration_path)\n",
    "    if not cap_cal.isOpened():\n",
    "        raise IOError(f\"Cannot open calibration video file at {calibration_path}\")\n",
    "\n",
    "    frames_for_calibration_count = 0\n",
    "    max_frames_to_process = 50 # Limit number of frames to check for chessboard - Increased from 100\n",
    "    processed_frames = 0\n",
    "\n",
    "    print(\"Processing calibration video frames...\")\n",
    "    while cap_cal.isOpened() and processed_frames < max_frames_to_process:\n",
    "        ret_cal, frame_cal = cap_cal.read()\n",
    "        processed_frames += 1\n",
    "        if not ret_cal:\n",
    "            break\n",
    "\n",
    "        gray_cal = cv2.cvtColor(frame_cal, cv2.COLOR_BGR2GRAY)\n",
    "        \n",
    "\n",
    "        finder_flags_sb = cv2.CALIB_CB_NORMALIZE_IMAGE\n",
    "\n",
    "        ret_corners, corners = cv2.findChessboardCornersSB(gray_cal, CHESSBOARD_CORNERS_ROWCOL, flags=finder_flags_sb)\n",
    "\n",
    "        # If found, add object points, image points (after refining them)\n",
    "        if ret_corners == True:\n",
    "            objpoints.append(objp)\n",
    "            \n",
    "            # Refine corner locations - cornerSubPix is still useful even with findChessboardCornersSB\n",
    "            corners2 = cv2.cornerSubPix(gray_cal, corners, (11,11), (-1,-1), \n",
    "                                        criteria=(cv2.TERM_CRITERIA_EPS + cv2.TERM_CRITERIA_MAX_ITER, 30, 0.001))\n",
    "            imgpoints.append(corners2)\n",
    "            frames_for_calibration_count += 1\n",
    "\n",
    "            # Draw and display the corners (optional, but very useful for debugging)\n",
    "            cv2.drawChessboardCorners(frame_cal, CHESSBOARD_CORNERS_ROWCOL, corners2, ret_corners)\n",
    "            cv2.imshow('Calibration Frame', frame_cal)\n",
    "            if cv2.waitKey(50) & 0xFF == ord('q'): # Display for 50ms, press 'q' to quit this loop early\n",
    "                 break\n",
    "            print(f\"Found corners in frame {processed_frames}, total frames with corners: {frames_for_calibration_count}\")\n",
    "        else:\n",
    "            if processed_frames % 10 == 0:\n",
    "                 print(f\"Processed {processed_frames} frames, corners not found in current frame.\")\n",
    "            # Display frame even if corners not found, to see what the camera sees\n",
    "            cv2.imshow('Calibration Frame', frame_cal)\n",
    "            if cv2.waitKey(1) & 0xFF == ord('q'): # Minimal wait\n",
    "                 break\n",
    "\n",
    "\n",
    "            if processed_frames <= 5:\n",
    "                debug_filename = f\"debug_calibration_frame_{processed_frames:03d}.png\"\n",
    "                \n",
    "                debug_save_path = os.path.join(POSTPROCESS_BASE_DIR, debug_filename)\n",
    "                try:\n",
    "                    cv2.imwrite(debug_save_path, frame_cal) # Save the color frame\n",
    "                    print(f\"Saved {debug_save_path} for inspection.\")\n",
    "                except Exception as e:\n",
    "                    print(f\"Error saving debug frame {debug_save_path}: {e}\")\n",
    "\n",
    "\n",
    "    cap_cal.release()\n",
    "    cv2.destroyWindow('Calibration Frame') # if imshow was used\n",
    "\n",
    "    if len(objpoints) > 0 and len(imgpoints) > 0:\n",
    "        print(f\"\\nPerforming camera calibration with {len(objpoints)} images...\")\n",
    "        rms_error, mtx, dist, rvecs, tvecs = cv2.calibrateCamera(objpoints, imgpoints, gray_cal.shape[::-1], None, None)\n",
    "        \n",
    "        print(f\"RMS re-projection error from calibrateCamera: {rms_error:.4f}\")\n",
    "\n",
    "        if rms_error >= 1.0: # Check if RMS error is high\n",
    "            print(f\"WARNING: High RMS re-projection error: {rms_error:.4f}. Calibration results (mtx, dist) may be inaccurate.\")\n",
    "            print(\"This can significantly affect the accuracy of undistortion and any measurements derived from it.\")\n",
    "            print(\"Suggestions to improve RMS error:\")\n",
    "            print(\"  1. Ensure CHESSBOARD_SQUARE_SIZE_MM is accurate for your physical board.\")\n",
    "            print(\"  2. Use a diverse set of high-quality calibration frames: vary the chessboard's position, orientation (tilt, rotation), and distance from the camera. Ensure the board is flat and well-lit.\")\n",
    "            print(\"  3. CRITICAL CHECK: Ensure 'FULL_BOARD_INNER_CORNERS_ROWCOL' accurately reflects your physical board's total inner corners.\")\n",
    "            print(f\"     Current CHESSBOARD_CORNERS_ROWCOL (detected pattern): {CHESSBOARD_CORNERS_ROWCOL}\")\n",
    "            print(f\"     Current FULL_BOARD_INNER_CORNERS_ROWCOL (physical board): {FULL_BOARD_INNER_CORNERS_ROWCOL}\")\n",
    "            print(f\"     The script is configured to map the detected {CHESSBOARD_CORNERS_ROWCOL} pattern to the top-right section of the {FULL_BOARD_INNER_CORNERS_ROWCOL} physical board.\")\n",
    "            print(\"     If this mapping, the physical board size, or the detected pattern visibility is incorrect, it can lead to high RMS error.\")\n",
    "            print(\"     For instance, if your physical board is smaller (e.g., exactly 7x7 inner corners), then FULL_BOARD_INNER_CORNERS_ROWCOL should be (7,7), and the offset logic would change (offset_x=0, offset_y=0).\")\n",
    "            print(\"Proceeding with potentially inaccurate calibration parameters...\")\n",
    "            # The script will continue using the mtx and dist obtained, despite the high error.\n",
    "        else: # rms_error < 1.0\n",
    "            print(f\"Camera calibrated successfully. RMS re-projection error: {rms_error:.4f}\")\n",
    "            \n",
    "        # Calculate re-projection error manually for each image (good for detailed insight)\n",
    "        mean_error_manual = 0\n",
    "        for i in range(len(objpoints)):\n",
    "            imgpoints2, _ = cv2.projectPoints(objpoints[i], rvecs[i], tvecs[i], mtx, dist)\n",
    "            error = cv2.norm(imgpoints[i], imgpoints2, cv2.NORM_L2)/len(imgpoints2)\n",
    "            mean_error_manual += error\n",
    "        if len(objpoints) > 0: # Avoid division by zero\n",
    "            print( \"Mean re-projection error (calculated manually per image): {}\".format(mean_error_manual/len(objpoints)) )\n",
    "            \n",
    "    else:\n",
    "        print(\"Not enough points for calibration. Check chessboard parameters and video content.\")\n",
    "        # mtx, dist remain None if this path is taken.\n",
    "\n",
    "\n",
    "if mtx is not None and dist is not None and (mm_per_pixel is None or mm_per_pixel == 0): # Recalculate if not loaded or zero\n",
    "    print(\"\\n--- Manual Frame Selection for mm_per_pixel Calculation ---\")\n",
    "    print(\"Press 's' to select the current frame for mm/pixel calculation.\")\n",
    "    print(\"Press 'n' or SPACE to view the next frame.\")\n",
    "    print(\"Press 'q' to quit selection without calculating mm/pixel.\")\n",
    "    \n",
    "    cap_cal_px = cv2.VideoCapture(calibration_path)\n",
    "    if not cap_cal_px.isOpened():\n",
    "        print(f\"Could not reopen calibration video for mm_per_pixel calculation: {calibration_path}\")\n",
    "    else:\n",
    "        found_frame_for_mm_pixel = False\n",
    "        temp_processed_frames = 0\n",
    "        \n",
    "        while cap_cal_px.isOpened():\n",
    "            ret_px, frame_px = cap_cal_px.read()\n",
    "            temp_processed_frames += 1\n",
    "            if not ret_px:\n",
    "                print(\"End of calibration video reached during mm/pixel frame selection.\")\n",
    "                break\n",
    "\n",
    "            h_px, w_px = frame_px.shape[:2]\n",
    "\n",
    "            newcameramtx, roi = cv2.getOptimalNewCameraMatrix(mtx, dist, (w_px,h_px), 1, (w_px,h_px))\n",
    "            dst_frame_px = cv2.undistort(frame_px, mtx, dist, None, newcameramtx)\n",
    "\n",
    "            display_frame_px = dst_frame_px.copy() # Work on a copy for drawing\n",
    "            \n",
    "            gray_px_undistorted = cv2.cvtColor(dst_frame_px, cv2.COLOR_BGR2GRAY)\n",
    "            \n",
    "            finder_flags_sb_px = cv2.CALIB_CB_NORMALIZE_IMAGE\n",
    "            ret_corners_px, corners_px = cv2.findChessboardCornersSB(gray_px_undistorted, CHESSBOARD_CORNERS_ROWCOL, flags=finder_flags_sb_px)\n",
    "\n",
    "            if ret_corners_px:\n",
    "                corners_px_refined = cv2.cornerSubPix(gray_px_undistorted, corners_px, (11,11), (-1,-1),\n",
    "                                                    criteria=(cv2.TERM_CRITERIA_EPS + cv2.TERM_CRITERIA_MAX_ITER, 30, 0.001))\n",
    "                # Draw corners on the display frame\n",
    "                cv2.drawChessboardCorners(display_frame_px, CHESSBOARD_CORNERS_ROWCOL, corners_px_refined, ret_corners_px)\n",
    "                \n",
    "            cv2.imshow('Select Frame for mm_per_pixel', display_frame_px)\n",
    "            key = cv2.waitKey(0) & 0xFF # Wait indefinitely for a key press\n",
    "\n",
    "            if key == ord('s'): # User selects this frame\n",
    "                if ret_corners_px:\n",
    "                    print(f\"Frame {temp_processed_frames} selected for mm/pixel calculation.\")\n",
    "                    # Proceed with calculation using corners_px_refined from this frame\n",
    "                    if CHESSBOARD_CORNERS_ROWCOL[0] > 1:\n",
    "                        pt1_pixel = corners_px_refined[0][0]\n",
    "                        pt2_pixel = corners_px_refined[CHESSBOARD_CORNERS_ROWCOL[0]-1][0]\n",
    "                        pixel_distance = np.sqrt((pt1_pixel[0] - pt2_pixel[0])**2 + (pt1_pixel[1] - pt2_pixel[1])**2)\n",
    "                        real_world_distance_mm = (CHESSBOARD_CORNERS_ROWCOL[0] - 1) * CHESSBOARD_SQUARE_SIZE_MM\n",
    "                        \n",
    "                        if pixel_distance > 0:\n",
    "                            mm_per_pixel = real_world_distance_mm / pixel_distance\n",
    "                            print(f\"Calculated mm_per_pixel: {mm_per_pixel:.4f} (using {CHESSBOARD_CORNERS_ROWCOL[0]-1} squares)\")\n",
    "                            found_frame_for_mm_pixel = True\n",
    "                            break # Exit the while loop for frame selection\n",
    "                        else:\n",
    "                            print(\"Pixel distance is zero in selected frame. Cannot calculate mm_per_pixel. Try another frame.\")\n",
    "                    else:\n",
    "                        print(\"Not enough corners along width (CHESSBOARD_CORNERS_ROWCOL[0] <= 1) to calculate mm_per_pixel.\")\n",
    "                        # Allow user to select another frame or quit\n",
    "                else:\n",
    "                    print(\"Corners not found in this frame. Cannot use for mm/pixel calculation. Press 'n' or SPACE for next, or 'q' to quit.\")\n",
    "            \n",
    "            elif key == ord('n') or key == ord(' '): # Next frame\n",
    "                continue\n",
    "            \n",
    "            elif key == ord('q'): # Quit selection\n",
    "                print(\"mm/pixel calculation aborted by user.\")\n",
    "                break\n",
    "            else: # Other key pressed\n",
    "                print(\"Invalid key. Press 's' to select, 'n' or SPACE for next, 'q' to quit.\")\n",
    "\n",
    "\n",
    "        cap_cal_px.release()\n",
    "        cv2.destroyWindow('Select Frame for mm_per_pixel') # Clean up the selection window\n",
    "\n",
    "        if not found_frame_for_mm_pixel:\n",
    "            print(\"No suitable frame was selected or found for mm_per_pixel calculation.\")\n",
    "            mm_per_pixel = 0 # Indicate failure or no selection\n",
    "\n",
    "\n",
    "if os.path.exists(calibration_data_file):\n",
    "\n",
    "    data = np.load(calibration_data_file)\n",
    "    if 'mm_per_pixel' not in data or (data['mm_per_pixel'] == 0 and mm_per_pixel != 0):\n",
    "        if mtx is not None and dist is not None: # Ensure mtx and dist are valid\n",
    "             print(f\"Updating calibration data file with new mm_per_pixel: {calibration_data_file}\")\n",
    "             np.savez(calibration_data_file, mtx=mtx, dist=dist, mm_per_pixel=mm_per_pixel)\n",
    "elif mtx is not None and dist is not None: # File didn't exist, save new calibration\n",
    "    print(f\"Saving new calibration data to: {calibration_data_file}\")\n",
    "    np.savez(calibration_data_file, mtx=mtx, dist=dist, mm_per_pixel=mm_per_pixel)\n",
    "\n",
    "\n",
    "\n",
    "if mtx is not None:\n",
    "    print(\"\\n--- Calibration Results ---\")\n",
    "    print(\"Camera Matrix (mtx):\\n\", mtx)\n",
    "    print(\"\\nDistortion Coefficients (dist):\\n\", dist)\n",
    "else:\n",
    "    print(\"\\n--- Calibration Not Performed or Failed ---\")\n",
    "\n",
    "if mm_per_pixel is not None and mm_per_pixel > 0:\n",
    "    print(f\"\\nMillimeters per pixel (at waterline, from chessboard): {mm_per_pixel:.4f} mm/pixel\")\n",
    "    print(f\"This means 1 pixel = {mm_per_pixel:.4f} mm\")\n",
    "else:\n",
    "    print(\"\\nMillimeters per pixel could not be determined.\")\n",
    "    print(\"Ensure chessboard is visible at waterline in calibration video and CHESSBOARD_CORNERS_ROWCOL[0] > 1.\")\n",
    "\n",
    "# Clean up any remaining OpenCV windows if they were used for display\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22c64a6a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Speed maps will be saved in a folder specific to test number: 7\n",
      "Warning: POSTPROCESS_BASE_DIR from Cell 1 is not defined. Using a default base path for PostProcess.\n",
      "Using default POSTPROCESS_BASE_DIR: \\\\sambaad.stud.ntnu.no\\arthursl\\.profil\\stud\\datasal\\Desktop\\Master\\Master\\Code\\PostProcess\n",
      "Speed map directory already exists: \\\\sambaad.stud.ntnu.no\\arthursl\\.profil\\stud\\datasal\\Desktop\\Master\\Master\\Code\\PostProcess\\SpeedMaps_papirtest7\n",
      "Video trimming enabled for 'papirtest7 - 34 sek.avi': Skipping from frame 1080 (0-indexed) up to 1559.\n",
      "Processing will resume at frame 1560 (0-indexed).\n",
      "Saved speed map to \\\\sambaad.stud.ntnu.no\\arthursl\\.profil\\stud\\datasal\\Desktop\\Master\\Master\\Code\\PostProcess\\SpeedMaps_papirtest7\\speed_map_frame_300.png\n",
      "Saved speed map to \\\\sambaad.stud.ntnu.no\\arthursl\\.profil\\stud\\datasal\\Desktop\\Master\\Master\\Code\\PostProcess\\SpeedMaps_papirtest7\\speed_map_frame_600.png\n",
      "Saved speed map to \\\\sambaad.stud.ntnu.no\\arthursl\\.profil\\stud\\datasal\\Desktop\\Master\\Master\\Code\\PostProcess\\SpeedMaps_papirtest7\\speed_map_frame_900.png\n",
      "Video reader at frame 1080 (0-indexed). Jumping to resume at frame 1560 (0-indexed).\n",
      "Optical flow points reset. User frame_idx set to 1559 (will be 1561 after read & increment).\n",
      "Saved speed map to \\\\sambaad.stud.ntnu.no\\arthursl\\.profil\\stud\\datasal\\Desktop\\Master\\Master\\Code\\PostProcess\\SpeedMaps_papirtest7\\speed_map_frame_1800.png\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import cv2\n",
    "import numpy as np  \n",
    "import os\n",
    "import re # Import regular expression module\n",
    "\n",
    "\n",
    "path = r\"\\\\sambaad.stud.ntnu.no\\arthursl\\.profil\\stud\\datasal\\Desktop\\Master\\Master\\Code\\PostProcess\\Resultater\\papirtest7 - 34 sek.avi\"\n",
    "\n",
    "mm_per_pixel = 0.42511\n",
    "\n",
    "FIXED_SPEED_MIN = 0.0       # m/s\n",
    "FIXED_SPEED_MAX = 0.4  \n",
    "\n",
    "\n",
    "\n",
    "backSub = cv2.createBackgroundSubtractorMOG2(history=500, varThreshold=12, detectShadows=False) # Original: varThreshold=16\n",
    "\n",
    "kernel = np.ones((5,5), np.uint8) # Original: (5,5)\n",
    "dilation_kernel = np.ones((3,3), np.uint8) # Kernel for dilation\n",
    "\n",
    "# Lucas–Kanade optical flow parameters\n",
    "feature_params = dict(maxCorners=100, qualityLevel=0.2, minDistance=15, blockSize=7)\n",
    "lk_params = dict(winSize=(15,15), maxLevel=2,\n",
    "                 criteria=(cv2.TERM_CRITERIA_EPS | cv2.TERM_CRITERIA_COUNT, 10, 0.03))\n",
    "\n",
    "MAX_POINT_AGE_FRAMES = 150 \n",
    "\n",
    "MIN_TRACK_AGE = 1  \n",
    "\n",
    "\n",
    "cap = cv2.VideoCapture(path)\n",
    "if not cap.isOpened():\n",
    "    raise IOError(f\"Cannot open video file at {path}\")\n",
    "\n",
    "ret, old_frame = cap.read()\n",
    "if not ret or old_frame is None:\n",
    "    raise IOError(\"Failed to read first frame from video.\")\n",
    "\n",
    "old_gray = cv2.cvtColor(old_frame, cv2.COLOR_BGR2GRAY)\n",
    "h, w = old_gray.shape[:2]\n",
    "\n",
    "\n",
    "first_frame_blur = cv2.GaussianBlur(old_gray, (9,9), 2)\n",
    "\n",
    "static_bad_regions_mask = cv2.Canny(first_frame_blur, 50, 150)\n",
    "# Dilate to make the wire mask thicker, ensure dilation_kernel is defined\n",
    "static_bad_regions_mask = cv2.dilate(static_bad_regions_mask, dilation_kernel, iterations=2)\n",
    "\n",
    "\n",
    "GRID_CELL_SIZE = 16 # pixels (adjust as needed)\n",
    "SAVE_SPEED_MAP_INTERVAL_SECONDS = 5 # Save speed map every 5 seconds\n",
    "\n",
    "\n",
    "video_filename_base = os.path.basename(path)\n",
    "match = re.search(r\"papirtest(\\d+)\", video_filename_base, re.IGNORECASE)\n",
    "\n",
    "speed_map_folder_name = \"SpeedMaps_general\" # Default folder name\n",
    "if match:\n",
    "    test_number = match.group(1)\n",
    "    speed_map_folder_name = f\"SpeedMaps_papirtest{test_number}\"\n",
    "    print(f\"Speed maps will be saved in a folder specific to test number: {test_number}\")\n",
    "else:\n",
    "    print(f\"No 'papirtest<number>' pattern found in filename. Speed maps will be saved in: {speed_map_folder_name}\")\n",
    "\n",
    "\n",
    "try:\n",
    "\n",
    "    if not (isinstance(POSTPROCESS_BASE_DIR, str) and POSTPROCESS_BASE_DIR):\n",
    "\n",
    "        print(\"Warning: POSTPROCESS_BASE_DIR from Cell 1 not found or invalid. Using current script's parent directory for PostProcess.\")\n",
    "\n",
    "        _default_postprocess_base = r\"\\\\sambaad.stud.ntnu.no\\arthursl\\.profil\\stud\\datasal\\Desktop\\Master\\Master\\Code\\PostProcess\"\n",
    "        print(f\"Using default POSTPROCESS_BASE_DIR: {_default_postprocess_base}\")\n",
    "        speed_map_save_path = os.path.join(_default_postprocess_base, speed_map_folder_name)\n",
    "    else:\n",
    "        speed_map_save_path = os.path.join(POSTPROCESS_BASE_DIR, speed_map_folder_name)\n",
    "except NameError:\n",
    "    # Fallback if POSTPROCESS_BASE_DIR is not defined at all\n",
    "    print(\"Warning: POSTPROCESS_BASE_DIR from Cell 1 is not defined. Using a default base path for PostProcess.\")\n",
    "    _default_postprocess_base = r\"\\\\sambaad.stud.ntnu.no\\arthursl\\.profil\\stud\\datasal\\Desktop\\Master\\Master\\Code\\PostProcess\" # Define a default\n",
    "    print(f\"Using default POSTPROCESS_BASE_DIR: {_default_postprocess_base}\")\n",
    "    speed_map_save_path = os.path.join(_default_postprocess_base, speed_map_folder_name)\n",
    "\n",
    "\n",
    "# speed_map_save_path = r\"C:\\Users\\HP\\OneDrive - NTNU\\Desktop\\Master\\Code\\PostProcess\\SpeedMaps\" # Ensure this folder exists\n",
    "if not os.path.exists(speed_map_save_path):\n",
    "    os.makedirs(speed_map_save_path)\n",
    "    print(f\"Created speed map directory: {speed_map_save_path}\")\n",
    "else:\n",
    "    print(f\"Speed map directory already exists: {speed_map_save_path}\")\n",
    "\n",
    "grid_cols = int(np.ceil(w / GRID_CELL_SIZE))\n",
    "grid_rows = int(np.ceil(h / GRID_CELL_SIZE))\n",
    "\n",
    "speed_sum_grid = np.zeros((grid_rows, grid_cols), dtype=np.float32)\n",
    "speed_count_grid = np.zeros((grid_rows, grid_cols), dtype=np.int32)\n",
    "\n",
    "TRIM_VIDEO = True # Set to True to enable skipping a section\n",
    "\n",
    "TRIM_SKIP_START_SECONDS = 18.0 \n",
    "TRIM_RESUME_AT_SECONDS = 26.0 \n",
    "\n",
    "skip_from_frame_0idx = -1\n",
    "resume_at_frame_0idx = -1\n",
    "can_trim_video = False # Internal flag to confirm trimming is possible\n",
    "\n",
    "x_min_roi = w // 4\n",
    "x_max_roi = 3 * w // 4\n",
    "\n",
    "\n",
    "y_intersect_left = 0\n",
    "if w > 0: # Avoid division by zero if w is 0\n",
    "    y_intersect_left = (h * x_min_roi) // w\n",
    "y_intersect_left = max(0, min(y_intersect_left, h // 2)) # Ensure it's within triangle bounds\n",
    "\n",
    "\n",
    "V2_x_float = float(w - 1)\n",
    "V2_y_float = 0.0\n",
    "V3_x_float = float(w // 2)\n",
    "V3_y_float = float(h // 2)\n",
    "\n",
    "y_intersect_right = 0\n",
    "den_slope_right = V3_x_float - V2_x_float\n",
    "if abs(den_slope_right) < 1e-6: # Handles case where V3_x is same as V2_x (e.g. w=2)\n",
    "    if x_max_roi == int(V2_x_float):\n",
    "         y_intersect_right = h // 2 \n",
    "    else:\n",
    "         y_intersect_right = 0 # Otherwise, no intersection or point is at y=0\n",
    "else:\n",
    "    slope_right = (V3_y_float - V2_y_float) / den_slope_right\n",
    "    # y = V2_y + slope_right * (x_max_roi - V2_x)\n",
    "    y_intersect_right = int(round(V2_y_float + slope_right * (float(x_max_roi) - V2_x_float)))\n",
    "y_intersect_right = max(0, min(y_intersect_right, h // 2)) # Ensure it's within triangle bounds\n",
    "\n",
    "\n",
    "\n",
    "triangle_roi = np.array([\n",
    "    [x_min_roi, 0],              \n",
    "    [x_max_roi, 0],                \n",
    "    [x_max_roi, y_intersect_right],\n",
    "    [w // 2, h],             \n",
    "    [x_min_roi, y_intersect_left] \n",
    "], dtype=np.int32)\n",
    "\n",
    "\n",
    "hough_params = dict(\n",
    "    dp=1.2, \n",
    "    minDist=10,  # Circles can be closer. Original: 10. Try 7 or 5 if pieces are close.\n",
    "    param1=50,  \n",
    "    param2=20,   # Original: 20.  15, 12, or 10 to make detection less strict.\n",
    "    minRadius=4, \n",
    "    maxRadius=25 \n",
    ")\n",
    "\n",
    "\n",
    "gray_blur = cv2.GaussianBlur(old_gray, (9,9), 2) # Original: (9,9), 2. Try (5,5), 1.5 or (7,7), 2\n",
    "circles = cv2.HoughCircles(\n",
    "    gray_blur, cv2.HOUGH_GRADIENT,\n",
    "    **hough_params\n",
    ")\n",
    "\n",
    "p0_birth_frames = [] # Stores birth frame_idx for each point in p0\n",
    "\n",
    "if circles is not None:\n",
    "    all_detected_pts = np.uint16(np.around(circles[0]))[:,:2]\n",
    "    # Keep only circles whose centers are inside the triangular ROI\n",
    "    pts_in_roi = []\n",
    "    for pt_candidate in all_detected_pts:\n",
    "        if cv2.pointPolygonTest(triangle_roi, tuple(pt_candidate), False) >= 0:\n",
    "            pts_in_roi.append(pt_candidate)\n",
    "    \n",
    "    if pts_in_roi:\n",
    "        pts = np.array(pts_in_roi, dtype=np.uint16)\n",
    "        p0 = pts.reshape(-1,1,2).astype(np.float32)\n",
    "        p0_birth_frames = [0] * len(p0) # Initial points born at frame 0\n",
    "    else:\n",
    "        p0 = np.empty((0,1,2), dtype=np.float32)\n",
    "else:\n",
    "    p0 = np.empty((0,1,2), dtype=np.float32)\n",
    "\n",
    "# Mask for drawing tracks\n",
    "mask = np.zeros_like(old_frame)\n",
    "\n",
    "# Parameters for dynamic re-detection\n",
    "detect_interval = 1    # every N frames\n",
    "min_features    = 5   \n",
    "frame_idx       = 0 \n",
    "\n",
    "# Compute display delay\n",
    "fps = cap.get(cv2.CAP_PROP_FPS)\n",
    "delay = int(1000 / fps) if fps > 0 else 30\n",
    "save_interval_frames = int(SAVE_SPEED_MAP_INTERVAL_SECONDS * fps) if fps > 0 else -1 # -1 to disable if fps is 0\n",
    "\n",
    "\n",
    "if TRIM_VIDEO: \n",
    "    if \"papirtest7\" in path: \n",
    "        if fps > 0:\n",
    "            skip_from_frame_0idx = int(TRIM_SKIP_START_SECONDS * fps)\n",
    "            resume_at_frame_0idx = int(TRIM_RESUME_AT_SECONDS * fps)\n",
    "            if skip_from_frame_0idx < resume_at_frame_0idx:\n",
    "                can_trim_video = True\n",
    "                print(f\"Video trimming enabled for '{os.path.basename(path)}': Skipping from frame {skip_from_frame_0idx} (0-indexed) up to {resume_at_frame_0idx - 1}.\")\n",
    "                print(f\"Processing will resume at frame {resume_at_frame_0idx} (0-indexed).\")\n",
    "            else:\n",
    "                print(f\"Warning: Trim start time is not before resume time. Trimming disabled for '{os.path.basename(path)}'.\")\n",
    "                TRIM_VIDEO = False \n",
    "        else: # fps <= 0\n",
    "            print(f\"Warning: FPS is 0, cannot calculate trim frames. Trimming disabled for '{os.path.basename(path)}'.\")\n",
    "            TRIM_VIDEO = False\n",
    "    else: # \"papirtest7\" not in path\n",
    "        print(f\"Filename '{os.path.basename(path)}' does not contain 'papirtest7'. Specific 18s-26s trimming disabled.\")\n",
    "        TRIM_VIDEO = False\n",
    "\n",
    "\n",
    "has_performed_skip = False # Flag to ensure skip jump happens only once per defined section\n",
    "\n",
    "# --- Function to generate and display speed map ---\n",
    "def display_speed_map(speed_sum, speed_count, frame_to_overlay, cell_size, mm_per_pixel_val, fps_val):\n",
    "    MIN_SAMPLES_FOR_RELIABLE_MAX = 15 # Min samples in a cell for its max speed to be considered \"stable\"\n",
    "\n",
    "    base_display = frame_to_overlay.copy()\n",
    "    if np.sum(speed_count) == 0:\n",
    "        cv2.putText(base_display, \"No speed data yet\", (10, 30), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (255, 255, 255), 2)\n",
    "        cv2.imshow('Speed Map', base_display)\n",
    "        #return base_display\n",
    "\n",
    "    avg_speed_grid_px_per_frame = np.zeros_like(speed_sum)\n",
    "    valid_cells = speed_count > 0 # Cells with at least one measurement\n",
    "    avg_speed_grid_px_per_frame[valid_cells] = speed_sum[valid_cells] / speed_count[valid_cells]\n",
    "\n",
    "    units = \"pixels/frame\"\n",
    "    avg_speed_grid_for_colormap = avg_speed_grid_px_per_frame.copy()\n",
    "    conversion_successful = False\n",
    "\n",
    "    if mm_per_pixel_val is not None and mm_per_pixel_val > 0 and fps_val is not None and fps_val > 0:\n",
    "        try:\n",
    "            avg_speed_mm_per_frame = avg_speed_grid_px_per_frame * float(mm_per_pixel_val)\n",
    "            avg_speed_mm_per_second = avg_speed_mm_per_frame * float(fps_val)\n",
    "            avg_speed_m_per_second = avg_speed_mm_per_second / 1000.0\n",
    "            avg_speed_grid_for_colormap = avg_speed_m_per_second\n",
    "            units = \"m/s\"\n",
    "            conversion_successful = True\n",
    "        except Exception as e:\n",
    "            print(f\"Error during speed conversion: {e}. Displaying in pixels/frame.\")\n",
    "    else:\n",
    "\n",
    "        pass\n",
    "\n",
    "\n",
    "    # Determine min/max for colormap normalization (using all valid cells)\n",
    "    min_for_colormap = 0\n",
    "    max_for_colormap = 0\n",
    "    if np.any(valid_cells):\n",
    "        min_for_colormap = np.min(avg_speed_grid_for_colormap[valid_cells])\n",
    "        max_for_colormap = np.max(avg_speed_grid_for_colormap[valid_cells])\n",
    "    \n",
    "    normalized_speed_grid = np.zeros_like(avg_speed_grid_for_colormap, dtype=np.uint8)\n",
    "    if max_for_colormap > min_for_colormap: # Avoid division by zero\n",
    "        normalized_speed_grid[valid_cells] = (\n",
    "            (avg_speed_grid_for_colormap[valid_cells] - min_for_colormap) / \n",
    "            (max_for_colormap - min_for_colormap) * 255\n",
    "        ).astype(np.uint8)\n",
    "    elif np.any(valid_cells): # If all speeds are the same (but non-zero count)\n",
    "         normalized_speed_grid[valid_cells] = 128 # Assign a mid-range color\n",
    "\n",
    "    colored_speed_map_small = cv2.applyColorMap(normalized_speed_grid, cv2.COLORMAP_JET)\n",
    "\n",
    "    speed_map_display_overlay = np.zeros_like(frame_to_overlay, dtype=np.uint8)\n",
    "    for r_idx in range(grid_rows):\n",
    "        for c_idx in range(grid_cols):\n",
    "            if speed_count[r_idx, c_idx] > 0: # Only draw for cells with data\n",
    "                start_x, start_y = c_idx * cell_size, r_idx * cell_size\n",
    "                end_x, end_y = min(start_x + cell_size, frame_to_overlay.shape[1]), min(start_y + cell_size, frame_to_overlay.shape[0])\n",
    "                \n",
    "                color_val = colored_speed_map_small[r_idx, c_idx]\n",
    "                cv2.rectangle(speed_map_display_overlay, (start_x, start_y), (end_x, end_y), \n",
    "                              (int(color_val[0]), int(color_val[1]), int(color_val[2])), -1)\n",
    "    \n",
    "    alpha = 0.6 \n",
    "    beta = 1.0 - alpha\n",
    "    combined_display = cv2.addWeighted(base_display, beta, speed_map_display_overlay, alpha, 0.0)\n",
    "    \n",
    "    # --- Text Display ---\n",
    "    text_y_offset = 30\n",
    "    cv2.putText(combined_display, f\"Speed ({units}):\", (10, text_y_offset), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 0, 0), 3, cv2.LINE_AA)\n",
    "    cv2.putText(combined_display, f\"Speed ({units}):\", (10, text_y_offset), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (255, 255, 255), 1, cv2.LINE_AA)\n",
    "    \n",
    "    # Min speed text (always from overall min)\n",
    "    min_for_text_display = min_for_colormap\n",
    "    text_y_offset += 25\n",
    "    cv2.putText(combined_display, f\"Min: {min_for_text_display:.3f}\", (10, text_y_offset), cv2.FONT_HERSHEY_SIMPLEX, 0.6, (0,0,0), 3, cv2.LINE_AA)\n",
    "    cv2.putText(combined_display, f\"Min: {min_for_text_display:.3f}\", (10, text_y_offset), cv2.FONT_HERSHEY_SIMPLEX, 0.6, (255,255,255), 1, cv2.LINE_AA)\n",
    "\n",
    "    # Max speed text (distinguish between stable and peak)\n",
    "    max_for_text_display = max_for_colormap # Default to overall max\n",
    "    max_label_qualifier = \"\"\n",
    "\n",
    "    reliable_cells_for_max = valid_cells & (speed_count >= MIN_SAMPLES_FOR_RELIABLE_MAX)\n",
    "    if np.any(reliable_cells_for_max):\n",
    "        max_for_text_display = np.max(avg_speed_grid_for_colormap[reliable_cells_for_max])\n",
    "        max_label_qualifier = \"(stable)\"\n",
    "    elif np.any(valid_cells): # Some data exists, but no cell is \"reliable\" yet\n",
    "        max_label_qualifier = \"(peak)\"\n",
    "\n",
    "\n",
    "    text_y_offset += 25\n",
    "    if np.any(valid_cells):\n",
    "        cv2.putText(combined_display, f\"Max: {max_for_text_display:.3f} {max_label_qualifier}\", (10, text_y_offset), cv2.FONT_HERSHEY_SIMPLEX, 0.6, (0,0,0), 3, cv2.LINE_AA)\n",
    "        cv2.putText(combined_display, f\"Max: {max_for_text_display:.3f} {max_label_qualifier}\", (10, text_y_offset), cv2.FONT_HERSHEY_SIMPLEX, 0.6, (255,255,255), 1, cv2.LINE_AA)\n",
    "    else: # No data at all\n",
    "        cv2.putText(combined_display, \"Max: N/A\", (10, text_y_offset), cv2.FONT_HERSHEY_SIMPLEX, 0.6, (0,0,0), 3, cv2.LINE_AA)\n",
    "        cv2.putText(combined_display, \"Max: N/A\", (10, text_y_offset), cv2.FONT_HERSHEY_SIMPLEX, 0.6, (255,255,255), 1, cv2.LINE_AA)\n",
    "\n",
    "\n",
    "    if not conversion_successful and (mm_per_pixel_val is None or mm_per_pixel_val <= 0):\n",
    "        text_y_offset += 25\n",
    "        cv2.putText(combined_display, \"mm/pixel not calibrated\", (10, text_y_offset), cv2.FONT_HERSHEY_SIMPLEX, 0.6, (0, 0, 255), 2, cv2.LINE_AA)\n",
    "        # build a vertical legend 256×20 px\n",
    "\n",
    "\n",
    "    #Legend \n",
    "    valid_idxs = np.where(valid_cells.flatten())[0]\n",
    "    if valid_idxs.size > 0:\n",
    "        # get the unique normalized values actually used\n",
    "        unique_vals = np.unique(normalized_speed_grid.flatten()[valid_cells.flatten()])\n",
    "        block_h = cell_size        # make each legend cell the same pixel height as grid cell\n",
    "        legend_h = block_h * len(unique_vals)\n",
    "        legend_w = cell_size        # square blocks\n",
    "        legend = np.zeros((legend_h, legend_w, 3), dtype=np.uint8)\n",
    "\n",
    "        for i, v in enumerate(unique_vals):\n",
    "            color = cv2.applyColorMap(\n",
    "                np.array([[v]], dtype=np.uint8), cv2.COLORMAP_JET\n",
    "            )[0,0]  # BGR triplet\n",
    "            y0 = i * block_h\n",
    "            legend[y0:y0+block_h, 0:legend_w] = color\n",
    "            # label at bottom‐left of each block\n",
    "            speed_val = min_for_colormap + (max_for_colormap-min_for_colormap)*(v/255)\n",
    "            cv2.putText(\n",
    "                legend, f\"{speed_val:.2f}\", (3, y0+block_h-3),\n",
    "                cv2.FONT_HERSHEY_SIMPLEX, 0.4, (255,255,255), 1\n",
    "            )\n",
    "\n",
    "        # overlay legend in bottom-right corner\n",
    "        H, W = combined_display.shape[:2]\n",
    "        if H >= legend_h and W >= legend_w:\n",
    "            combined_display[H-legend_h:H, W-legend_w:W] = legend\n",
    "        \n",
    "    cv2.imshow('Speed Map', combined_display)\n",
    "    return combined_display\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "while True:\n",
    "\n",
    "    if TRIM_VIDEO and can_trim_video and not has_performed_skip:\n",
    "        current_read_pos_0idx = int(cap.get(cv2.CAP_PROP_POS_FRAMES)) # 0-indexed position of next frame to be read\n",
    "\n",
    "        # Check if the reader is about to enter or is within the defined skip zone\n",
    "        if current_read_pos_0idx >= skip_from_frame_0idx and current_read_pos_0idx < resume_at_frame_0idx:\n",
    "            print(f\"Video reader at frame {current_read_pos_0idx} (0-indexed). Jumping to resume at frame {resume_at_frame_0idx} (0-indexed).\")\n",
    "            cap.set(cv2.CAP_PROP_POS_FRAMES, float(resume_at_frame_0idx))\n",
    "            has_performed_skip = True # Mark that the jump has been made for this section\n",
    "\n",
    "\n",
    "            frame_idx = resume_at_frame_0idx -1 \n",
    "            \n",
    "            # Reset optical flow points as the sequence is broken\n",
    "            p0 = np.empty((0,1,2), dtype=np.float32)\n",
    "            p0_birth_frames = []\n",
    "            print(f\"Optical flow points reset. User frame_idx set to {frame_idx} (will be {resume_at_frame_0idx+1} after read & increment).\")\n",
    "            # The 'old_gray' will be correctly updated from the frame read after the jump.\n",
    "\n",
    "\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        break\n",
    "\n",
    "    frame_idx += 1 # This is the 1-based index of the 'frame' just read\n",
    "    frame_gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    # Update background mask each frame\n",
    "    fgmask = backSub.apply(frame)\n",
    "    fgmask = cv2.morphologyEx(fgmask, cv2.MORPH_OPEN, kernel)\n",
    "    fgmask = cv2.dilate(fgmask, dilation_kernel, iterations=1) # Dilate to make foreground more robust\n",
    "\n",
    "    # Periodically detect new circles only in the triangular ROI\n",
    "    if frame_idx % detect_interval == 0 or len(p0) < min_features:\n",
    "        # SUGGESTION 2: Experiment with GaussianBlur parameters (same as above)\n",
    "        blur = cv2.GaussianBlur(frame_gray, (9,9), 2) # Original: (9,9), 2. Try (5,5), 1.5 or (7,7), 2\n",
    "        circles = cv2.HoughCircles(\n",
    "            blur, cv2.HOUGH_GRADIENT,\n",
    "            **hough_params # Use unified parameters\n",
    "        )\n",
    "        if circles is not None:\n",
    "            all_pts_re_detected = np.uint16(np.around(circles[0]))[:,:2]\n",
    "            # Only keep new detections from the triangular ROI\n",
    "            new_pts_in_roi = []\n",
    "            for pt_candidate in all_pts_re_detected:\n",
    "                if cv2.pointPolygonTest(triangle_roi, tuple(pt_candidate), False) >= 0:\n",
    "                    new_pts_in_roi.append(pt_candidate)\n",
    "\n",
    "            if new_pts_in_roi: # Check if any points were actually detected in the region\n",
    "                new_pts_array = np.array(new_pts_in_roi, dtype=np.uint16)\n",
    "                new_pts = new_pts_array.reshape(-1,1,2).astype(np.float32)\n",
    "                \n",
    "                new_birth_frames = [frame_idx] * len(new_pts)\n",
    "                if p0.size == 0:\n",
    "                    p0 = new_pts\n",
    "                    p0_birth_frames = new_birth_frames\n",
    "                else:\n",
    "                    p0 = np.concatenate((p0, new_pts), axis=0)\n",
    "                    p0_birth_frames.extend(new_birth_frames)\n",
    "\n",
    "\n",
    "\n",
    "    # If we have points to track, compute optical flow\n",
    "    if len(p0) > 0:\n",
    "        p1, st, err = cv2.calcOpticalFlowPyrLK(old_gray, frame_gray, p0, None, **lk_params)\n",
    "        if p1 is None or st is None:\n",
    "            # No points tracked in this frame\n",
    "            p0 = np.empty((0,1,2), dtype=np.float32) # Clear points if flow fails\n",
    "            p0_birth_frames = []\n",
    "            old_gray = frame_gray.copy()\n",
    "            cv2.imshow('Optical Flow Tracking', frame) # Show frame\n",
    "            if cv2.waitKey(delay) & 0xFF == ord('q'):\n",
    "                break\n",
    "            continue\n",
    "\n",
    "        # Select only successfully tracked points\n",
    "        st_flat = st.flatten()\n",
    "        good_new_candidates = p1[st_flat == 1]\n",
    "        good_old_candidates = p0[st_flat == 1]\n",
    "        # Filter corresponding birth frames\n",
    "        good_birth_frames_candidates = [p0_birth_frames[i] for i, status in enumerate(st_flat) if status == 1]\n",
    "\n",
    "        # Prune points that have moved off-frame, are too old, or are on the background/static bad regions\n",
    "        \n",
    "        surviving_good_new = []\n",
    "        surviving_good_old = []\n",
    "        surviving_birth_frames = []\n",
    "\n",
    "        if good_new_candidates.size > 0: # Check if there are any candidates before iterating\n",
    "            for i_candidate, pt_new in enumerate(good_new_candidates):\n",
    "                x_coord_int, y_coord_int = pt_new.ravel().astype(int) # Use int for indexing mask\n",
    "                y_new_float = pt_new.ravel()[1] # Get new y for movement check\n",
    "                \n",
    "                pt_old = good_old_candidates[i_candidate]\n",
    "                y_old_float = pt_old.ravel()[1] # Get old y for movement check\n",
    "\n",
    "                birth_frame = good_birth_frames_candidates[i_candidate]\n",
    "                age = frame_idx - birth_frame\n",
    "\n",
    "                # Check bounds, age, if in foreground, NOT in a static bad region, AND NOT moving upwards\n",
    "                if (x_coord_int >= 0 and x_coord_int < w and\n",
    "                    y_coord_int >= 0 and y_coord_int < h and\n",
    "                    age <= MAX_POINT_AGE_FRAMES and\n",
    "                    fgmask[y_coord_int, x_coord_int] == 255 and # Must be in MOG2 foreground\n",
    "                    static_bad_regions_mask[y_coord_int, x_coord_int] == 0 and # Must NOT be on a static bad region\n",
    "                    # SUGGESTION 5: Relax upward movement constraint for testing\n",
    "                    y_new_float >= y_old_float-1): # Original: y_new_float >= y_old_float. Try y_new_float >= y_old_float - 1\n",
    "                    surviving_good_new.append(pt_new)\n",
    "                    surviving_good_old.append(pt_old) # Use pt_old directly\n",
    "                    surviving_birth_frames.append(birth_frame)\n",
    "        \n",
    "        # Update points based on survivors\n",
    "        if surviving_good_new:\n",
    "            good_new = np.array(surviving_good_new).reshape(-1, 1, 2)\n",
    "            good_old = np.array(surviving_good_old).reshape(-1, 1, 2)\n",
    "            \n",
    "            # Draw the tracks for surviving points\n",
    "            for i, (new, old) in enumerate(zip(good_new, good_old)):\n",
    "                birth_frame = surviving_birth_frames[i]\n",
    "                age = frame_idx - birth_frame\n",
    "                if age <= MIN_TRACK_AGE:\n",
    "                    continue\n",
    "                x_new, y_new = new.ravel().astype(int)\n",
    "                x_old, y_old = old.ravel().astype(int)\n",
    "                mask = cv2.line(mask, (x_new, y_new), (x_old, y_old), (0,255,0), 2)\n",
    "                frame = cv2.circle(frame, (x_new, y_new), 3, (0,0,255), -1)\n",
    "\n",
    "                # --- Accumulate Speed Data ---\n",
    "                dx = float(x_new - x_old)\n",
    "                dy = float(y_new - y_old)\n",
    "                speed = np.sqrt(dx**2 + dy**2) # Speed in pixels/frame\n",
    "\n",
    "                # Use midpoint for cell location\n",
    "                mid_x, mid_y = (x_old + x_new) // 2, (y_old + y_new) // 2\n",
    "                \n",
    "                cell_c = mid_x // GRID_CELL_SIZE\n",
    "                cell_r = mid_y // GRID_CELL_SIZE\n",
    "\n",
    "                if 0 <= cell_r < grid_rows and 0 <= cell_c < grid_cols:\n",
    "                    speed_sum_grid[cell_r, cell_c] += speed\n",
    "                    speed_count_grid[cell_r, cell_c] += 1\n",
    "                # --- End Accumulate Speed Data ---\n",
    "            \n",
    "            p0 = good_new.reshape(-1,1,2)\n",
    "            p0_birth_frames = surviving_birth_frames\n",
    "        else: # No points survived this frame's tracking\n",
    "            p0 = np.empty((0,1,2), dtype=np.float32)\n",
    "            p0_birth_frames = []\n",
    "\n",
    "        # Overlay the tracks on the frame (ALWAYS do this to show persistent mask)\n",
    "        img = cv2.add(frame, mask)\n",
    "        cv2.imshow('Optical Flow Tracking', img)\n",
    "        \n",
    "\n",
    "        speed_map_image = display_speed_map(speed_sum_grid, speed_count_grid, frame.copy(), GRID_CELL_SIZE, mm_per_pixel, fps)\n",
    "\n",
    "        # Save the speed map image periodically\n",
    "        if save_interval_frames > 0 and frame_idx % save_interval_frames == 0:\n",
    "            timestamp = frame_idx # Or use a more descriptive timestamp if needed\n",
    "            filename = os.path.join(speed_map_save_path, f\"speed_map_frame_{timestamp}.png\")\n",
    "            cv2.imwrite(filename, speed_map_image)\n",
    "            print(f\"Saved speed map to {filename}\")\n",
    "\n",
    "\n",
    "    else:\n",
    "\n",
    "        img = cv2.add(frame, mask)\n",
    "        cv2.imshow('Optical Flow Tracking', img)\n",
    "        \n",
    "        # Display the current speed map (even if no new points this frame)\n",
    "        speed_map_image = display_speed_map(speed_sum_grid, speed_count_grid, frame.copy(), GRID_CELL_SIZE, mm_per_pixel, fps)\n",
    "        \n",
    "        # Save the speed map image periodically (also if no new points)\n",
    "        if save_interval_frames > 0 and frame_idx % save_interval_frames == 0:\n",
    "            timestamp = frame_idx \n",
    "            filename = os.path.join(speed_map_save_path, f\"speed_map_frame_{timestamp}.png\")\n",
    "            cv2.imwrite(filename, speed_map_image)\n",
    "            print(f\"Saved speed map to {filename}\")\n",
    "        # p0 and p0_birth_frames remain empty\n",
    "\n",
    "    old_gray = frame_gray.copy()\n",
    "\n",
    "    # Exit on 'q'\n",
    "    if cv2.waitKey(delay) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "# Cleanup\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
