{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0dc80f1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This file is to produce the wave documentation data and plot ir\n",
    "# 6 wave probes were placed along the pool, 5 in the middle, and one between the middle and the wall at the half way to find transverse waves\n",
    "# All wave documentation data is in C:\\Users\\HP\\OneDrive - NTNU\\Desktop\\Master\\Code\\PostProcess\\Resultater\\WaveDocumentation\n",
    "#The tank is 25m long, 2.5m wide and 0.7m deep. Code should take reflection\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "from scipy.optimize import fsolve\n",
    "import os # Added for potential file system operations, though not used in this snippet\n",
    "import pandas as pd # For handling experimental data\n",
    "import scipy.signal # For Butterworth filter\n",
    "from apread import APReader # Added for reading .bin files\n",
    "\n",
    "wavedocumentation_path = r\"H:\\CodeLÃ¥nePC\\Resultater\\WaveDocumentation\"\n",
    "\n",
    "water_depth = 0.7 #m\n",
    "\n",
    "# Store wave probe x-positions in a dictionary for easier access\n",
    "wave_probe_positions_x = {\n",
    "    \"WP3\": 5,\n",
    "    \"WP4\": 9,\n",
    "    \"WP5\": 11,\n",
    "    \"WP6\": 13,\n",
    "    \"WP7\": 17,\n",
    "    \"WP8\": 11,\n",
    "}\n",
    "\n",
    "#Distance from wall (y-coordinate, tank width is 2.5m)\n",
    "WP3_y = 1.25 #m\n",
    "WP4_y = 1.25 #m\n",
    "WP5_y = 1.25 #m\n",
    "WP6_y = 1.25 #m \n",
    "WP7_y = 1.25 #m\n",
    "WP8_y = 0.625 #m #Off centre\n",
    "\n",
    "# Physical constants\n",
    "g = 9.81  # m/s^2 (acceleration due to gravity)\n",
    "L_tank = 22.0  # m (length of the tank)\n",
    "\n",
    "# --- Data Loading Functions ---\n",
    "def search_file(file_name, root_folder):\n",
    "    \"\"\"Searches for a file in the root_folder and its subdirectories.\"\"\"\n",
    "    for r, d, f_list in os.walk(root_folder):\n",
    "        if file_name in f_list:\n",
    "            return os.path.join(r, file_name)\n",
    "    raise FileNotFoundError(f\"File '{file_name}' not found in '{root_folder}' or its subdirectories.\")\n",
    "\n",
    "\n",
    "def bin_to_dataframe(full_file_path):\n",
    "    \"\"\"\n",
    "    Reads a .bin file using APReader and converts it to a pandas DataFrame.\n",
    "    Identifies channels by names. Looks for a 'Time' channel and wave probe channels (WP3-WP8).\n",
    "    \"\"\"\n",
    "    try:\n",
    "        reader = APReader(full_file_path)\n",
    "    except Exception as e:\n",
    "        raise IOError(f\"Error opening or reading file {full_file_path} with APReader: {e}\")\n",
    "\n",
    "    data_dict = {}\n",
    "    raw_channel_names = []\n",
    "    for ch in reader.Channels:\n",
    "        try:\n",
    "            name_parts = str(ch).split('\"')\n",
    "            if len(name_parts) > 1:\n",
    "                raw_channel_names.append(name_parts[1])\n",
    "            else:\n",
    "                raw_channel_names.append(str(ch.Name))\n",
    "        except Exception:\n",
    "            try:\n",
    "                raw_channel_names.append(str(ch.Name))\n",
    "            except AttributeError:\n",
    "                raw_channel_names.append(f\"UnnamedChannel_{len(raw_channel_names)}\")\n",
    "\n",
    "    for i, ch in enumerate(reader.Channels):\n",
    "        data_dict[raw_channel_names[i]] = ch.data\n",
    "\n",
    "    time_key_found = None\n",
    "    temp_df_keys = list(data_dict.keys())\n",
    "    for key in temp_df_keys:\n",
    "        if \"time\" in key.lower():\n",
    "            time_key_found = key\n",
    "            break\n",
    "    \n",
    "    if not time_key_found:\n",
    "        raise ValueError(f\"No 'Time' channel found in {full_file_path}. Available channels: {temp_df_keys}\")\n",
    "\n",
    "    df = pd.DataFrame(data_dict)\n",
    "\n",
    "    desired_wp_columns = [wp for wp in wave_probe_positions_x.keys() if wp in df.columns]\n",
    "    final_columns_to_keep = [time_key_found] + desired_wp_columns\n",
    "    \n",
    "    df_subset = df[final_columns_to_keep]\n",
    "    df_subset = df_subset.rename(columns={time_key_found: \"Time\"})\n",
    "    \n",
    "    return df_subset\n",
    "\n",
    "# --- End Data Loading Functions --\n",
    "# \n",
    "\n",
    "def solve_dispersion_for_k(period, water_depth, g_const):\n",
    "    \"\"\"\n",
    "    Solves the dispersion relation for the wave number k.\n",
    "    omega^2 = g * k * tanh(k * h)\n",
    "    Args:\n",
    "        period (float): Wave period in seconds.\n",
    "        water_depth (float): Water depth in meters.\n",
    "        g_const (float): Acceleration due to gravity.\n",
    "    Returns:\n",
    "        float: Wave number k (rad/m), or np.nan if not solvable.\n",
    "    \"\"\"\n",
    "    if period <= 0 or water_depth <= 0:\n",
    "        return np.nan\n",
    "    \n",
    "    omega = 2 * np.pi / period\n",
    "    \n",
    "    # Equation to solve: g * k * tanh(k * h) - omega^2 = 0\n",
    "    def dispersion_eq(k_val):\n",
    "        if k_val <= 0: # k must be positive\n",
    "            return np.inf # Return a large number if k is non-physical to guide solver\n",
    "        return g_const * k_val * np.tanh(k_val * water_depth) - omega**2\n",
    "\n",
    "    # Initial guess for k (deep water approximation, or other reasonable guess)\n",
    "    k_guess = omega**2 / g_const  # Deep water\n",
    "    if k_guess * water_depth < 1: # If more like shallow water, adjust guess\n",
    "        k_guess_shallow = omega / np.sqrt(g_const * water_depth)\n",
    "        # Check if shallow water guess is more appropriate or if deep water guess is too small\n",
    "        if k_guess <= 0.01 : k_guess = k_guess_shallow\n",
    "\n",
    "    if k_guess <= 0: k_guess = 0.01 # Ensure guess is positive\n",
    "\n",
    "    try:\n",
    "        k_solution, infodict, ier, mesg = fsolve(dispersion_eq, k_guess, full_output=True)\n",
    "        if ier == 1 and k_solution[0] > 0: # Check if fsolve converged and k is positive\n",
    "            return k_solution[0]\n",
    "        else:\n",
    "            # Try a different guess or a bounded solver if fsolve fails.\n",
    "            # For simplicity, we'll return NaN on basic fsolve failure here.\n",
    "            # print(f\"Warning: Dispersion solver did not converge for T={period:.2f}s. Message: {mesg}\")\n",
    "            return np.nan\n",
    "    except Exception as e:\n",
    "        # print(f\"Error in dispersion solver for T={period:.2f}s: {e}\")\n",
    "        return np.nan\n",
    "\n",
    "def extract_variable_from_filename(file_name, variable):\n",
    "    # Expecting format: date-period-steepness(info)#test.bin\n",
    "    # Example: 1701-0_525-40(WaveDoc)#1.bin\n",
    "    # parts[0] = date (1701)\n",
    "    # parts[1] = period (0_525)\n",
    "    # parts[2] = steepness(info)#test.bin (40(WaveDoc)#1.bin)\n",
    "    \n",
    "    parts = file_name.split('-', 2) # Split into at most 3 parts\n",
    "    if len(parts) < 3:\n",
    "        raise ValueError(f\"Invalid file name format. Expected 'date-period-steepness(info)#test.bin', got: {file_name}\")\n",
    "\n",
    "    date = parts[0]\n",
    "    period_str = parts[1].replace(\"_\", \".\") # Period is the second part\n",
    "    \n",
    "    # The third part contains steepness, optional info, and test number\n",
    "    steepness_and_test_part = parts[2]\n",
    "    \n",
    "    steepness_raw, hash_separator, test_part_with_ext = steepness_and_test_part.partition('#')\n",
    "    \n",
    "    if not hash_separator: # '#' was not found\n",
    "        # This implies the format might be date-period-steepness.bin (no test number)\n",
    "        # or the structure is different than expected.\n",
    "        # For now, assume if # is missing, the rest is steepness_raw and test is unknown.\n",
    "        test = \"Unknown\"\n",
    "        # Check if .bin is present in steepness_raw and remove it\n",
    "        if steepness_raw.endswith(\".bin\"):\n",
    "            steepness_raw = steepness_raw[:-4]\n",
    "        # If we are here, it means there was no '#' separating steepness_raw from test_part\n",
    "        # So, test_part_with_ext would be empty from partition.\n",
    "    else:\n",
    "        test = test_part_with_ext.replace(\".bin\", \"\")\n",
    "\n",
    "    # Parse steepness_val and info_val from steepness_raw\n",
    "    if '(' in steepness_raw and ')' in steepness_raw:\n",
    "        i = steepness_raw.find('(')\n",
    "        j = steepness_raw.find(')', i)\n",
    "        steepness_val_str = steepness_raw[:i]\n",
    "        info_val = steepness_raw[i+1:j]\n",
    "    elif '-' in steepness_raw: # Check for \"value-info\" if not \"(info)\"\n",
    "        # This assumes a hyphen within the steepness_raw part is for info.\n",
    "        # e.g. \"S0_02-SomeInfo\" -> steepness_val_str=\"S0_02\", info_val=\"SomeInfo\"\n",
    "        potential_steep_parts = steepness_raw.split('-', 1)\n",
    "        if len(potential_steep_parts) == 2:\n",
    "             steepness_val_str = potential_steep_parts[0]\n",
    "             info_val = potential_steep_parts[1]\n",
    "        else: # Only one part, or leading hyphen\n",
    "            steepness_val_str = steepness_raw\n",
    "            info_val = None\n",
    "    else:\n",
    "        steepness_val_str = steepness_raw\n",
    "        info_val = None\n",
    "\n",
    "    # Clean the steepness value string (e.g. S0_02 -> 0.02)\n",
    "    # A simple approach: if it starts with S and then a digit or '_', remove S.\n",
    "    if steepness_val_str and isinstance(steepness_val_str, str) and \\\n",
    "       steepness_val_str.startswith(('S', 's')) and len(steepness_val_str) > 1 and \\\n",
    "       (steepness_val_str[1].isdigit() or steepness_val_str[1] == '_'):\n",
    "        steepness_val_str = steepness_val_str[1:]\n",
    "    \n",
    "    steepness_val_str = steepness_val_str.replace(\"_\", \".\") if steepness_val_str else None\n",
    "\n",
    "    var = variable.lower()\n",
    "    if var == \"date\":\n",
    "        return date\n",
    "    elif var == \"velocity\":\n",
    "        return np.nan # Velocity is not in this filename format\n",
    "    elif var == \"period\":\n",
    "        try:\n",
    "            return float(period_str)\n",
    "        except (ValueError, TypeError):\n",
    "            return period_str # Return as string if not floatable\n",
    "    elif var == \"steepness\":\n",
    "        try:\n",
    "            return float(steepness_val_str)\n",
    "        except (ValueError, TypeError):\n",
    "            return steepness_val_str # Return as string if not floatable\n",
    "    elif var == \"info\":\n",
    "        return info_val\n",
    "    elif var in (\"test\", \"testnumber\"):\n",
    "        if test == \"Unknown\": return test\n",
    "        try:\n",
    "            return int(test)\n",
    "        except ValueError:\n",
    "            return test # Return as string if not intable\n",
    "    else:\n",
    "        raise ValueError(f\"Invalid variable requested: {variable}.\")\n",
    "\n",
    "\n",
    "def calculate_average_steady_state_amplitude(full_file_path, channel_name, \n",
    "                                           wave_period_T=None, \n",
    "                                           steepness_val_from_filename=None, # New: e.g., 40.0\n",
    "                                           steady_state_start_time=20.0, \n",
    "                                           filter_order=4, cutoff_freq_hz=5.0,\n",
    "                                           initial_skip_periods=15, # Fallback\n",
    "                                           end_buffer_periods=10,   # Fallback\n",
    "                                           target_amplitude_factor_for_start=0.3, \n",
    "                                           num_peaks_skip_start=10,\n",
    "                                           num_peaks_skip_end=0, # Changed from 10 to 0\n",
    "                                           reflection_time_delay_sec=10.0): # New parameter for delay\n",
    "    \"\"\"\n",
    "    Calculates the average of steady-state amplitudes for a given wave probe signal.\n",
    "    The analysis window is dynamically determined by:\n",
    "    1. Start: Finding when signal reaches target_amplitude_factor_for_start * input_amplitude, then skipping num_peaks_skip_start peaks.\n",
    "    2. End: Ending num_peaks_skip_end peaks before calculated reflection.\n",
    "    Falls back to time-based windowing if dynamic determination fails.\n",
    "\n",
    "    Args:\n",
    "        full_file_path (str): The full path to the .bin data file.\n",
    "        channel_name (str): The name of the wave probe channel (e.g., \"WP3\").\n",
    "        wave_period_T (float, optional): Nominal wave period in seconds.\n",
    "        steepness_val_from_filename (float, optional): Steepness value (e.g., 40.0 for S_HL*1000) from filename.\n",
    "        steady_state_start_time (float): Fallback start time.\n",
    "        filter_order (int): Order of the Butterworth filter.\n",
    "        cutoff_freq_hz (float): Cutoff frequency for the Butterworth low-pass filter.\n",
    "        initial_skip_periods (int): Fallback: Number of wave periods to skip from t=0.\n",
    "        end_buffer_periods (int): Fallback: Number of wave periods before reflection to end analysis.\n",
    "        target_amplitude_factor_for_start (float): Factor of input_amplitude to define ramp-up threshold.\n",
    "        num_peaks_skip_start (int): Number of peaks to skip after ramp-up threshold is met.\n",
    "        num_peaks_skip_end (int): Number of peaks to skip before reflection.\n",
    "        reflection_time_delay_sec (float): Seconds to add to the calculated reflection arrival time.\n",
    "\n",
    "    Returns:\n",
    "        float: The average of the steady-state amplitudes, or np.nan if not calculable.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        df = bin_to_dataframe(full_file_path)\n",
    "    except Exception as e:\n",
    "        # print(f\"Debug: Error loading data for {channel_name} from {os.path.basename(full_file_path)}: {e}\")\n",
    "        return np.nan\n",
    "\n",
    "    if channel_name not in df.columns:\n",
    "        return np.nan\n",
    "    if \"Time\" not in df.columns:\n",
    "        return np.nan\n",
    "\n",
    "    time_signal = df[\"Time\"].values\n",
    "    wave_signal = df[channel_name].values\n",
    "\n",
    "    if len(time_signal) < 10 or len(wave_signal) < 10:\n",
    "        return np.nan\n",
    "\n",
    "    fs = 1.0 / np.mean(np.diff(time_signal))\n",
    "    if not (fs > 0 and np.isfinite(fs)):\n",
    "        return np.nan\n",
    "    \n",
    "    nyquist_freq = 0.5 * fs\n",
    "    actual_cutoff_freq_hz = cutoff_freq_hz\n",
    "    if cutoff_freq_hz >= nyquist_freq:\n",
    "        actual_cutoff_freq_hz = nyquist_freq * 0.95 \n",
    "        if actual_cutoff_freq_hz <= 0.01:\n",
    "            return np.nan \n",
    "\n",
    "    Wn = actual_cutoff_freq_hz / nyquist_freq\n",
    "    if not (0 < Wn < 1):\n",
    "        filtered_signal = wave_signal\n",
    "    else:\n",
    "        b, a = scipy.signal.butter(filter_order, Wn, btype='low', analog=False)\n",
    "        if len(wave_signal) > 3 * filter_order: \n",
    "            try:\n",
    "                filtered_signal = scipy.signal.filtfilt(b, a, wave_signal)\n",
    "            except ValueError: \n",
    "                filtered_signal = wave_signal \n",
    "        else:\n",
    "            filtered_signal = wave_signal\n",
    "\n",
    "    filtered_signal = filtered_signal - np.mean(filtered_signal) # Detrend\n",
    "\n",
    "    # --- Calculate Input Amplitude for dynamic windowing ---\n",
    "    calculated_input_amplitude = np.nan\n",
    "    if wave_period_T is not None and isinstance(wave_period_T, (float, int)) and wave_period_T > 0 and \\\n",
    "       steepness_val_from_filename is not None and isinstance(steepness_val_from_filename, (float, int)):\n",
    "        k_val_ia = solve_dispersion_for_k(wave_period_T, water_depth, g)\n",
    "        if k_val_ia is not None and not np.isnan(k_val_ia) and k_val_ia > 0:\n",
    "            wavelength_ia = 2 * np.pi / k_val_ia\n",
    "            actual_steepness_HL_ia = steepness_val_from_filename / 1000.0\n",
    "            calculated_input_amplitude = actual_steepness_HL_ia * wavelength_ia / 2.0\n",
    "\n",
    "    # --- Determine Analysis Start Time (analysis_start_t) ---\n",
    "    analysis_start_t = -1 # Flag for not set\n",
    "    \n",
    "    # Try dynamic start time\n",
    "    if not np.isnan(calculated_input_amplitude) and calculated_input_amplitude > 0:\n",
    "        target_signal_level_for_start = target_amplitude_factor_for_start * calculated_input_amplitude\n",
    "        # Find first time signal exceeds this (positive) level\n",
    "        indices_above_target = np.where(filtered_signal >= target_signal_level_for_start)[0]\n",
    "        \n",
    "        if len(indices_above_target) > 0:\n",
    "            first_index_above_target = indices_above_target[0]\n",
    "            \n",
    "            # Find peaks from this point onwards\n",
    "            min_peak_dist_start = int(fs * wave_period_T * 0.4) if (wave_period_T and wave_period_T > 0 and fs > 0) else int(fs * 0.1)\n",
    "            if min_peak_dist_start < 1: min_peak_dist_start = 1\n",
    "            \n",
    "            peaks_after_threshold_indices_rel, _ = scipy.signal.find_peaks(\n",
    "                filtered_signal[first_index_above_target:], \n",
    "                height=0.0005, # Keep a minimal height threshold\n",
    "                distance=min_peak_dist_start\n",
    "            )\n",
    "            peaks_after_threshold_indices_abs = peaks_after_threshold_indices_rel + first_index_above_target\n",
    "            \n",
    "            if len(peaks_after_threshold_indices_abs) > num_peaks_skip_start:\n",
    "                # The (num_peaks_skip_start)-th peak in 0-indexed array is the one to start AFTER\n",
    "                # So, the (num_peaks_skip_start)-th index is the (num_peaks_skip_start + 1)-th peak\n",
    "                start_peak_abs_index = peaks_after_threshold_indices_abs[num_peaks_skip_start]\n",
    "                analysis_start_t = time_signal[start_peak_abs_index]\n",
    "                # print(f\"Debug ({channel_name}): Dynamic start time set to {analysis_start_t:.2f}s (peak after {num_peaks_skip_start} skips).\")\n",
    "\n",
    "    # Fallback start time if dynamic failed\n",
    "    if analysis_start_t == -1:\n",
    "        if wave_period_T is not None and isinstance(wave_period_T, (float, int)) and wave_period_T > 0:\n",
    "            analysis_start_t = initial_skip_periods * wave_period_T\n",
    "            # print(f\"Debug ({channel_name}): Fallback start time (T-based): {analysis_start_t:.2f}s.\")\n",
    "        else:\n",
    "            analysis_start_t = steady_state_start_time # Absolute fallback\n",
    "            # print(f\"Debug ({channel_name}): Fallback start time (fixed): {analysis_start_t:.2f}s.\")\n",
    "\n",
    "    # --- Calculate reflection arrival time for the current channel (as before) ---\n",
    "    reflection_arrival_time_current_channel = np.nan\n",
    "    if wave_period_T is not None and isinstance(wave_period_T, (float, int)) and wave_period_T > 0:\n",
    "        k_val = solve_dispersion_for_k(wave_period_T, water_depth, g)\n",
    "        if k_val is not None and not np.isnan(k_val) and k_val > 0:\n",
    "            omega = 2 * np.pi / wave_period_T\n",
    "            C = omega / k_val \n",
    "            n_val = 0.5 * (1 + (2 * k_val * water_depth) / np.sinh(2 * k_val * water_depth))\n",
    "            Cg = n_val * C \n",
    "            if Cg > 1e-6:\n",
    "                wp_x_position = wave_probe_positions_x.get(channel_name)\n",
    "                if wp_x_position is not None:\n",
    "                    time_to_reach_probe = wp_x_position / Cg\n",
    "                    time_probe_to_wall_and_back = (2 * (L_tank - wp_x_position)) / Cg\n",
    "                    if time_probe_to_wall_and_back >= 0:\n",
    "                        reflection_arrival_time_current_channel = time_to_reach_probe + time_probe_to_wall_and_back\n",
    "                        if not np.isnan(reflection_arrival_time_current_channel): # Add delay if valid\n",
    "                            reflection_arrival_time_current_channel += reflection_time_delay_sec\n",
    "\n",
    "    # --- Determine Analysis End Time (analysis_end_t) ---\n",
    "    analysis_end_t = -1 # Flag for not set\n",
    "\n",
    "    # Try dynamic end time\n",
    "    if not np.isnan(reflection_arrival_time_current_channel):\n",
    "        idx_reflection_arrival = np.searchsorted(time_signal, reflection_arrival_time_current_channel)\n",
    "        if idx_reflection_arrival > 0: # Ensure reflection is not at the very beginning\n",
    "            min_peak_dist_end = int(fs * wave_period_T * 0.4) if (wave_period_T and wave_period_T > 0 and fs > 0) else int(fs * 0.1)\n",
    "            if min_peak_dist_end < 1: min_peak_dist_end = 1\n",
    "\n",
    "            peaks_before_reflection_indices_abs, _ = scipy.signal.find_peaks(\n",
    "                filtered_signal[:idx_reflection_arrival],\n",
    "                height=0.0005,\n",
    "                distance=min_peak_dist_end\n",
    "            )\n",
    "            if len(peaks_before_reflection_indices_abs) > num_peaks_skip_end:\n",
    "                # End at the peak that is (num_peaks_skip_end + 1) from the last peak before reflection\n",
    "                # e.g. if num_peaks_skip_end = 5, use index -6 (6th from last)\n",
    "                end_peak_abs_index = peaks_before_reflection_indices_abs[-(num_peaks_skip_end + 1)]\n",
    "                analysis_end_t = time_signal[end_peak_abs_index]\n",
    "                # print(f\"Debug ({channel_name}): Dynamic end time set to {analysis_end_t:.2f}s (peak before {num_peaks_skip_end} skips from reflection).\")\n",
    "\n",
    "    # Fallback end time if dynamic failed or no reflection\n",
    "    if analysis_end_t == -1:\n",
    "        fallback_end_t = time_signal[-1]\n",
    "        if not np.isnan(reflection_arrival_time_current_channel):\n",
    "            if wave_period_T is not None and isinstance(wave_period_T, (float, int)) and wave_period_T > 0:\n",
    "                potential_end_t = reflection_arrival_time_current_channel - (end_buffer_periods * wave_period_T)\n",
    "                fallback_end_t = min(fallback_end_t, potential_end_t)\n",
    "            else:\n",
    "                fallback_end_t = min(fallback_end_t, reflection_arrival_time_current_channel)\n",
    "        analysis_end_t = fallback_end_t\n",
    "        # print(f\"Debug ({channel_name}): Fallback end time set to {analysis_end_t:.2f}s.\")\n",
    "\n",
    "\n",
    "    # Ensure analysis_end_t is not before analysis_start_t\n",
    "    if analysis_end_t <= analysis_start_t:\n",
    "        # print(f\"Debug ({channel_name}): Invalid window. End time {analysis_end_t:.2f}s <= Start time {analysis_start_t:.2f}s.\")\n",
    "        return np.nan\n",
    "\n",
    "    start_index_steady = np.searchsorted(time_signal, analysis_start_t)\n",
    "    abs_end_index_for_analysis = np.searchsorted(time_signal, analysis_end_t, side='right') \n",
    "    \n",
    "    if start_index_steady >= abs_end_index_for_analysis:\n",
    "        # print(f\"Debug ({channel_name}): No valid analysis window after indexing. Start_idx {start_index_steady}, End_idx {abs_end_index_for_analysis}. Times: Start {analysis_start_t:.2f}s, End {analysis_end_t:.2f}s\")\n",
    "        return np.nan\n",
    "    \n",
    "    steady_signal = filtered_signal[start_index_steady:abs_end_index_for_analysis]\n",
    "    \n",
    "    if len(steady_signal) < 2: \n",
    "        return np.nan\n",
    "\n",
    "    min_peak_height = 0.0005 \n",
    "    \n",
    "    if wave_period_T is not None and wave_period_T > 0 and fs > 0:\n",
    "        min_peak_distance = int(fs * wave_period_T * 0.4) \n",
    "    else:\n",
    "        if actual_cutoff_freq_hz > 0:\n",
    "             min_peak_distance = int(fs / (actual_cutoff_freq_hz * 4)) \n",
    "        else: \n",
    "            min_peak_distance = int(fs * 0.1) \n",
    "\n",
    "    if min_peak_distance < 1: min_peak_distance = 1\n",
    "\n",
    "    peaks_indices, _ = scipy.signal.find_peaks(steady_signal, height=min_peak_height, distance=min_peak_distance)\n",
    "    \n",
    "    if len(peaks_indices) == 0:\n",
    "        # print(f\"Debug ({channel_name}): No peaks found in the final analysis window {analysis_start_t:.2f}s - {analysis_end_t:.2f}s.\")\n",
    "        return np.nan\n",
    "        \n",
    "    amplitudes = steady_signal[peaks_indices]\n",
    "    # num_peaks_to_average = 5 # This is removed, average all peaks in window\n",
    "    \n",
    "    # if len(amplitudes) < num_peaks_to_average: # This check is no longer relevant in this way\n",
    "    #     if len(amplitudes) == 0: return np.nan \n",
    "    \n",
    "    # amplitudes_to_average = amplitudes[:num_peaks_to_average] # Average all\n",
    "    average_amplitude = np.mean(amplitudes) # Average all found peaks\n",
    "    \n",
    "    return average_amplitude\n",
    "\n",
    "\n",
    "def create_dataframe():\n",
    "    \"\"\"\n",
    "    Creates a DataFrame by processing all .bin files in the wavedocumentation_path.\n",
    "    Extracts metadata from filenames and calculates average steady-state amplitudes for each wave probe.\n",
    "    Also calculates inputAmplitude based on period and steepness.\n",
    "\n",
    "    Returns:\n",
    "        pandas.DataFrame: DataFrame containing the processed data.\n",
    "    \"\"\"\n",
    "    all_data_rows = []\n",
    "    \n",
    "    if not os.path.isdir(wavedocumentation_path):\n",
    "        print(f\"Error: Directory not found - {wavedocumentation_path}\")\n",
    "        return pd.DataFrame()\n",
    "\n",
    "    print(f\"Processing files in: {wavedocumentation_path}\")\n",
    "    files_to_process = [f for f in os.listdir(wavedocumentation_path) if f.endswith(\".bin\")]\n",
    "    print(f\"Found {len(files_to_process)} .bin files.\")\n",
    "\n",
    "    for i, filename in enumerate(files_to_process):\n",
    "        print(f\"Processing file {i+1}/{len(files_to_process)}: {filename}\")\n",
    "        full_file_path = os.path.join(wavedocumentation_path, filename)\n",
    "        \n",
    "        row_data = {}\n",
    "        period_value = None\n",
    "        steepness_from_file = None\n",
    "        try:\n",
    "            row_data[\"filename\"] = filename\n",
    "            row_data[\"date\"] = extract_variable_from_filename(filename, \"date\")\n",
    "            row_data[\"velocity\"] = extract_variable_from_filename(filename, \"velocity\") # Will be NaN\n",
    "            period_value = extract_variable_from_filename(filename, \"period\")\n",
    "            row_data[\"period\"] = period_value\n",
    "            steepness_from_file = extract_variable_from_filename(filename, \"steepness\")\n",
    "            row_data[\"steepness\"] = steepness_from_file # This is the scaled value, e.g., 40.0\n",
    "            row_data[\"info\"] = extract_variable_from_filename(filename, \"info\")\n",
    "            row_data[\"test_number\"] = extract_variable_from_filename(filename, \"testnumber\")\n",
    "        except ValueError as e:\n",
    "            print(f\"  Skipping file {filename} due to error extracting variables: {e}\")\n",
    "            continue\n",
    "\n",
    "        # Calculate inputAmplitude\n",
    "        input_amplitude_calculated = np.nan\n",
    "        if isinstance(period_value, (int, float)) and period_value > 0 and \\\n",
    "           isinstance(steepness_from_file, (int, float)):\n",
    "            \n",
    "            k_val = solve_dispersion_for_k(period_value, water_depth, g)\n",
    "            \n",
    "            if k_val is not None and not np.isnan(k_val) and k_val > 0:\n",
    "                wavelength = 2 * np.pi / k_val\n",
    "                # Assuming steepness_from_file is S_HL * 1000 (e.g., 40 means S_HL = 0.04)\n",
    "                # S_HL = H/L = 2a/L\n",
    "                # a = (steepness_from_file / 1000.0) * wavelength / 2.0\n",
    "                actual_steepness_HL = steepness_from_file / 1000.0\n",
    "                input_amplitude_calculated = actual_steepness_HL * wavelength / 2.0\n",
    "            else:\n",
    "                # print(f\"  Could not calculate k for P={period_value}, S={steepness_from_file} in {filename}\")\n",
    "                pass # k_val is nan or invalid\n",
    "        \n",
    "        row_data[\"inputAmplitude\"] = input_amplitude_calculated\n",
    "\n",
    "        for wp_name in wave_probe_positions_x.keys():\n",
    "            avg_amp = calculate_average_steady_state_amplitude(\n",
    "                full_file_path, \n",
    "                wp_name,    \n",
    "                wave_period_T=period_value if isinstance(period_value, (int, float)) else None,\n",
    "                steepness_val_from_filename=steepness_from_file if isinstance(steepness_from_file, (float, int)) else None, # New\n",
    "                steady_state_start_time=20.0, \n",
    "                filter_order=4,             \n",
    "                cutoff_freq_hz=5.0,\n",
    "                initial_skip_periods=15, \n",
    "                end_buffer_periods=10,\n",
    "                # Defaults for new params are used in function def if not specified here\n",
    "                # target_amplitude_factor_for_start=0.5,\n",
    "                # num_peaks_skip_start=10,\n",
    "                # num_peaks_skip_end=5\n",
    "            )\n",
    "            row_data[f\"{wp_name}_Avg_Amp\"] = avg_amp\n",
    "        \n",
    "        all_data_rows.append(row_data)\n",
    "            \n",
    "    if not all_data_rows:\n",
    "        print(\"No .bin files were successfully processed or found in the directory.\")\n",
    "        return pd.DataFrame()\n",
    "\n",
    "    df = pd.DataFrame(all_data_rows)\n",
    "    print(\"\\nDataFrame created successfully.\")\n",
    "    # Example: print summary if you want to see it when script runs\n",
    "    # print(df.info())\n",
    "    # print(df.head())\n",
    "    return df\n",
    "\n",
    "def test_plot_average_steady_state_amplitude(full_file_path, channel_name, \n",
    "                                           wave_period_T=None, \n",
    "                                           steepness_val_from_filename=None, # New\n",
    "                                           steady_state_start_time=20.0, \n",
    "                                           filter_order=4, cutoff_freq_hz=5.0,\n",
    "                                           initial_skip_periods=15, end_buffer_periods=10,\n",
    "                                           target_amplitude_factor_for_start=0.3, \n",
    "                                           num_peaks_skip_start=10,             # New for plot mirroring\n",
    "                                           num_peaks_skip_end=0,              # Changed from 10 to 0\n",
    "                                           reflection_time_delay_sec_plot=10.0): # New parameter for plot delay\n",
    "    \"\"\"\n",
    "    Visually tests signal processing steps with a three-plot layout:\n",
    "    1. Raw and Filtered signal with general WP8 reflection context.\n",
    "    2. WP8-specific \"ideal\" sample window (after transients, before WP8 reflection) & its peak analysis.\n",
    "       Shows full detrended signal in background, with analysis window highlighted.\n",
    "    3. Visualization of the data and peaks used by `calculate_average_steady_state_amplitude` for the current `channel_name`.\n",
    "       Shows full detrended signal in background, with analysis window highlighted.\n",
    "    Reflection times are calculated from t=0 (wave generation) to reflection arrival at the probe.\n",
    "    Args:\n",
    "        full_file_path (str): The full path to the .bin data file.\n",
    "        channel_name (str): The name of the wave probe channel (e.g., \"WP3\").\n",
    "        wave_period_T (float, optional): Nominal wave period in seconds.\n",
    "        steepness_val_from_filename (float, optional): Steepness value (e.g., 40.0) from filename for input_amp calc.\n",
    "        steady_state_start_time (float): Time in seconds to consider for start of steady state.\n",
    "        filter_order (int): Order of the Butterworth filter.\n",
    "        cutoff_freq_hz (float): Cutoff frequency for the Butterworth low-pass filter.\n",
    "        initial_skip_periods (int): Fallback: Number of wave periods to skip from t=0 (for Plot 3).\n",
    "        end_buffer_periods (int): Fallback: Number of wave periods before reflection to end analysis (for Plot 3).\n",
    "        target_amplitude_factor_for_start (float): Factor for dynamic start threshold.\n",
    "        num_peaks_skip_start (int): Peaks to skip for dynamic start.\n",
    "        num_peaks_skip_end (int): Peaks to skip for dynamic end.\n",
    "        reflection_time_delay_sec_plot (float): Seconds to add to calculated reflection time for plotting.\n",
    "    \"\"\"\n",
    "    print(f\"\\n--- Test Plotting for {channel_name} from {os.path.basename(full_file_path)} ---\")\n",
    "    try:\n",
    "        df = bin_to_dataframe(full_file_path)\n",
    "    except Exception as e:\n",
    "        print(f\"Error loading data: {e}\")\n",
    "        return\n",
    "\n",
    "    if channel_name not in df.columns or \"Time\" not in df.columns:\n",
    "        print(f\"Channel {channel_name} or Time not found in DataFrame. Available columns: {df.columns.tolist()}\")\n",
    "        return\n",
    "\n",
    "    time_signal = df[\"Time\"].values\n",
    "    wave_signal = df[channel_name].values # This ensures data for the correct channel is used.\n",
    "\n",
    "    # Calculate fs early for use in diagnostic print\n",
    "    fs = 0 \n",
    "    if len(time_signal) > 1:\n",
    "        fs = 1.0 / np.mean(np.diff(time_signal))\n",
    "    else:\n",
    "        print(\"Warning: Cannot calculate sampling frequency, time_signal too short.\")\n",
    "        # Potentially return or handle error, for now, fs will be 0 if not calculable\n",
    "\n",
    "    # Diagnostic print:\n",
    "    print(f\"Successfully loaded data for {channel_name}. First 5 raw values: {wave_signal[:5]}\")\n",
    "    # Check if initial part of signal is mostly constant or has few unique values\n",
    "    # Ensure fs is valid before using it for slicing\n",
    "    if fs > 0 and len(wave_signal) > 5 : \n",
    "        slice_end_index = min(len(wave_signal), int(fs * 2)) # Ensure slice doesn't exceed array bounds\n",
    "        if slice_end_index > 0 and len(np.unique(wave_signal[:slice_end_index])) < 10:\n",
    "            print(f\"Warning: Initial part of signal for {channel_name} (up to {slice_end_index} samples / ~2s) has very few unique values. This might indicate an issue, a very stable signal, or a delay before wave arrival.\")\n",
    "    elif len(wave_signal) > 5 and len(np.unique(wave_signal[:5])) < 3 : # Fallback check if fs is not valid\n",
    "        print(f\"Warning: First 5 samples for {channel_name} have very few unique values. This might indicate an issue or a very stable signal.\")\n",
    "\n",
    "\n",
    "    if len(time_signal) < 10:\n",
    "        print(\"Insufficient data points.\")\n",
    "        return\n",
    "\n",
    "    plt.figure(figsize=(15, 15)) # Adjusted figure size for clarity\n",
    "\n",
    "    # --- Common Calculations ---\n",
    "    # fs is already calculated above\n",
    "    \n",
    "    filtered_signal_data = wave_signal \n",
    "    actual_cutoff_for_label = cutoff_freq_hz \n",
    "\n",
    "    if not (fs > 0 and np.isfinite(fs)):\n",
    "        print(f\"Invalid sampling frequency ({fs:.2f} Hz). Using unfiltered signal.\")\n",
    "    else: \n",
    "        nyquist_freq = 0.5 * fs\n",
    "        processing_cutoff = cutoff_freq_hz \n",
    "        if processing_cutoff >= nyquist_freq:\n",
    "            adjusted_cutoff = nyquist_freq * 0.95\n",
    "            actual_cutoff_for_label = adjusted_cutoff \n",
    "            if adjusted_cutoff <= 0.01:\n",
    "                print(f\"Adjusted cutoff ({adjusted_cutoff:.2f} Hz) too low. Using unfiltered signal.\")\n",
    "                processing_cutoff = -1 \n",
    "            else: \n",
    "                processing_cutoff = adjusted_cutoff\n",
    "        \n",
    "        if processing_cutoff > 0: \n",
    "            Wn = processing_cutoff / nyquist_freq\n",
    "            if not (0 < Wn < 1):\n",
    "                print(f\"Invalid Wn ({Wn:.2f}). Using unfiltered signal.\")\n",
    "            else:\n",
    "                b, a = scipy.signal.butter(filter_order, Wn, btype='low', analog=False)\n",
    "                if len(wave_signal) > 3 * filter_order: \n",
    "                    try:\n",
    "                        filtered_signal_data = scipy.signal.filtfilt(b, a, wave_signal) \n",
    "                    except ValueError as ve:\n",
    "                         print(f\"filtfilt error: {ve}. Using unfiltered signal.\")\n",
    "                else:\n",
    "                    print(f\"Signal too short for filtfilt. Using unfiltered signal.\")\n",
    "        else: \n",
    "             print(f\"Not filtering due to invalid cutoff ({processing_cutoff}).\")\n",
    "\n",
    "    detrended_filtered_signal = filtered_signal_data - np.mean(filtered_signal_data)\n",
    "\n",
    "    # Calculate reflection time for WP8 (general context)\n",
    "    reflection_arrival_time_WP8_context = np.nan\n",
    "    if wave_period_T and wave_period_T > 0 and \"WP8\" in wave_probe_positions_x:\n",
    "        k_val_wp8 = solve_dispersion_for_k(wave_period_T, water_depth, g)\n",
    "        if k_val_wp8 and not np.isnan(k_val_wp8) and k_val_wp8 > 0:\n",
    "            omega_wp8 = 2 * np.pi / wave_period_T\n",
    "            C_wp8 = omega_wp8 / k_val_wp8\n",
    "            n_wp8 = 0.5 * (1 + (2 * k_val_wp8 * water_depth) / np.sinh(2 * k_val_wp8 * water_depth))\n",
    "            Cg_wp8 = n_wp8 * C_wp8\n",
    "            if Cg_wp8 > 1e-6:\n",
    "                wp8_x_pos = wave_probe_positions_x[\"WP8\"]\n",
    "                time_to_reach_WP8 = wp8_x_pos / Cg_wp8\n",
    "                time_WP8_to_wall_and_back = (2 * (L_tank - wp8_x_pos)) / Cg_wp8\n",
    "                if time_WP8_to_wall_and_back >= 0: # Ensure WP8 is not considered beyond the tank end\n",
    "                    reflection_arrival_time_WP8_context = time_to_reach_WP8 + time_WP8_to_wall_and_back\n",
    "                    print(f\"Context: WP8 reflection (from t=0 at wavemaker) expected around {reflection_arrival_time_WP8_context:.2f}s (Cg={Cg_wp8:.2f}m/s).\")\n",
    "                else:\n",
    "                    print(f\"Context: WP8 ({wp8_x_pos}m) is at or beyond tank end ({L_tank}m) for reflection path calculation.\")\n",
    "            else:\n",
    "                print(\"Context: WP8 Cg_wp8 is too small for reflection calculation.\")\n",
    "        else:\n",
    "            print(\"Context: WP8 k_val_wp8 not solvable for reflection calculation.\")\n",
    "\n",
    "    # Effective start time for \"ideal\" window (Plot 2)\n",
    "    effective_plot_start_time = steady_state_start_time # Default\n",
    "    if wave_period_T and wave_period_T > 0:\n",
    "        effective_plot_start_time = steady_state_start_time + (10 * wave_period_T)\n",
    "        print(f\"Plot 2 'ideal' window starts at {effective_plot_start_time:.2f}s (steady_state_start_time + 10*T).\")\n",
    "    else:\n",
    "        print(f\"Plot 2 'ideal' window starts at {effective_plot_start_time:.2f}s (using steady_state_start_time).\")\n",
    "\n",
    "    \n",
    "    min_peak_height_param = 0.0005\n",
    "    num_peaks_to_average_param = 5\n",
    "\n",
    "    # --- Subplot 1: Raw and Filtered Signal ---\n",
    "    plt.subplot(3, 1, 1)\n",
    "    plt.plot(time_signal, wave_signal, label=f'Raw {channel_name}', color='blue', alpha=0.6)\n",
    "    plt.plot(time_signal, filtered_signal_data, label=f'Filtered (Cutoff: {actual_cutoff_for_label:.2f}Hz)', color='red', linewidth=1.2)\n",
    "    if not np.isnan(reflection_arrival_time_WP8_context):\n",
    "        plt.axvline(reflection_arrival_time_WP8_context, color='darkcyan', linestyle=':', linewidth=1.5, label=f'WP8 Reflection Context ({reflection_arrival_time_WP8_context:.2f}s)')\n",
    "    plt.title(f'1. Raw and Filtered Signal ({channel_name})')\n",
    "    plt.xlabel('Time (s)')\n",
    "    plt.ylabel('Amplitude (m)')\n",
    "    plt.legend(fontsize='small')\n",
    "    plt.grid(True, linestyle=':', alpha=0.5)\n",
    "\n",
    "    # --- Subplot 2: WP8-Specific Ideal Sample Window ---\n",
    "    plt.subplot(3, 1, 2)\n",
    "    plot2_start_time = effective_plot_start_time\n",
    "    plot2_end_time = reflection_arrival_time_WP8_context if not np.isnan(reflection_arrival_time_WP8_context) else time_signal[-1]\n",
    "    \n",
    "    # Plot full detrended filtered signal as background\n",
    "    plt.plot(time_signal, detrended_filtered_signal, label='Full Detrended Signal', color='lightgrey', alpha=0.7, zorder=1)\n",
    "\n",
    "    idx_start_plot2 = np.searchsorted(time_signal, plot2_start_time)\n",
    "    idx_end_plot2 = np.searchsorted(time_signal, plot2_end_time)\n",
    "\n",
    "    if idx_start_plot2 < idx_end_plot2 and idx_start_plot2 < len(detrended_filtered_signal):\n",
    "        time_plot2 = time_signal[idx_start_plot2:idx_end_plot2]\n",
    "        signal_plot2 = detrended_filtered_signal[idx_start_plot2:idx_end_plot2]\n",
    "        if len(signal_plot2) >= 2:\n",
    "            plt.plot(time_plot2, signal_plot2, label='Signal in WP8 Ideal Window', color='purple', linewidth=1.5, zorder=2)\n",
    "            \n",
    "            min_dist_p2 = int(fs * wave_period_T * 0.4) if (wave_period_T and wave_period_T > 0 and fs > 0) else int(fs * 0.1)\n",
    "            if min_dist_p2 < 1: min_dist_p2 = 1\n",
    "            peaks_idx_p2, _ = scipy.signal.find_peaks(signal_plot2, height=min_peak_height_param, distance=min_dist_p2)\n",
    "            \n",
    "            if len(peaks_idx_p2) > 0:\n",
    "                peak_t_p2 = time_plot2[peaks_idx_p2]\n",
    "                peak_a_p2 = signal_plot2[peaks_idx_p2]\n",
    "                plt.plot(peak_t_p2, peak_a_p2, \"x\", color='orange', markersize=5, label='Peaks in Window')\n",
    "                amps_to_avg_p2 = peak_a_p2[:num_peaks_to_average_param]\n",
    "                if len(amps_to_avg_p2) > 0:\n",
    "                    avg_p2 = np.mean(amps_to_avg_p2)\n",
    "                    print(f\"Plot 2: Avg for WP8 ideal window ({plot2_start_time:.2f}s to {plot2_end_time:.2f}s): {avg_p2:.6f} m\")\n",
    "                    plt.plot(peak_t_p2[:len(amps_to_avg_p2)], amps_to_avg_p2, \"o\", mfc='red', mec='k', ms=7, label=f'Avg Peaks ({avg_p2:.4f}m)', zorder=3)\n",
    "            else: print(\"Plot 2: No peaks in WP8 ideal window.\")\n",
    "        else: print(\"Plot 2: WP8 ideal window signal too short.\")\n",
    "    else: print(\"Plot 2: WP8 ideal window invalid or empty.\")\n",
    "\n",
    "    plt.axvline(plot2_start_time, color='gray', linestyle='--', label=f'Ideal Start ({plot2_start_time:.2f}s)')\n",
    "    if not np.isnan(reflection_arrival_time_WP8_context):\n",
    "        plt.axvline(reflection_arrival_time_WP8_context, color='darkcyan', linestyle=':', label=f'WP8 Reflect End ({reflection_arrival_time_WP8_context:.2f}s)')\n",
    "    plt.title('2. WP8-Specific Ideal Sample Window & Analysis')\n",
    "    plt.xlabel('Time (s)')\n",
    "    plt.ylabel('Amplitude (m)')\n",
    "    plt.legend(fontsize='small')\n",
    "    plt.grid(True, linestyle=':', alpha=0.5)\n",
    "\n",
    "    # --- Subplot 3: Visualization of `calculate_average_steady_state_amplitude` for `channel_name` ---\n",
    "    plt.subplot(3, 1, 3)\n",
    "    \n",
    "    plt.plot(time_signal, detrended_filtered_signal, label='Full Detrended Signal', color='lightgrey', alpha=0.7, zorder=1)\n",
    "\n",
    "    # --- Replicate dynamic window logic for Plot 3 visualization ---\n",
    "    plot3_start_t = -1\n",
    "    plot3_end_t = -1\n",
    "    \n",
    "    # Calculate Input Amplitude for dynamic windowing (for plotting)\n",
    "    calculated_input_amplitude_plot3 = np.nan\n",
    "    if wave_period_T is not None and isinstance(wave_period_T, (float, int)) and wave_period_T > 0 and \\\n",
    "       steepness_val_from_filename is not None and isinstance(steepness_val_from_filename, (float, int)):\n",
    "        k_val_ia_p3 = solve_dispersion_for_k(wave_period_T, water_depth, g)\n",
    "        if k_val_ia_p3 is not None and not np.isnan(k_val_ia_p3) and k_val_ia_p3 > 0:\n",
    "            wavelength_ia_p3 = 2 * np.pi / k_val_ia_p3\n",
    "            actual_steepness_HL_ia_p3 = steepness_val_from_filename / 1000.0\n",
    "            calculated_input_amplitude_plot3 = actual_steepness_HL_ia_p3 * wavelength_ia_p3 / 2.0\n",
    "            plt.axhline(target_amplitude_factor_for_start * calculated_input_amplitude_plot3, color='cyan', linestyle=':', label=f'{int(target_amplitude_factor_for_start*100)}% Input Amp ({target_amplitude_factor_for_start * calculated_input_amplitude_plot3:.4f}m)')\n",
    "\n",
    "    # Dynamic Start Time for Plot 3\n",
    "    first_index_above_target_plot3 = -1\n",
    "    peaks_after_threshold_indices_abs_plot3 = []\n",
    "    if not np.isnan(calculated_input_amplitude_plot3) and calculated_input_amplitude_plot3 > 0:\n",
    "        target_signal_level_plot3 = target_amplitude_factor_for_start * calculated_input_amplitude_plot3\n",
    "        indices_above_target_plot3 = np.where(detrended_filtered_signal >= target_signal_level_plot3)[0]\n",
    "        \n",
    "        if len(indices_above_target_plot3) > 0:\n",
    "            first_index_above_target_plot3 = indices_above_target_plot3[0]\n",
    "            plt.plot(time_signal[first_index_above_target_plot3], detrended_filtered_signal[first_index_above_target_plot3], 'cD', ms=8, label='Threshold Met')\n",
    "\n",
    "            min_peak_dist_p3_start = int(fs * wave_period_T * 0.4) if (wave_period_T and wave_period_T > 0 and fs > 0) else int(fs * 0.1)\n",
    "            if min_peak_dist_p3_start < 1: min_peak_dist_p3_start = 1\n",
    "            \n",
    "            peaks_rel_p3, _ = scipy.signal.find_peaks(\n",
    "                detrended_filtered_signal[first_index_above_target_plot3:], \n",
    "                height=min_peak_height_param, distance=min_peak_dist_p3_start)\n",
    "            peaks_after_threshold_indices_abs_plot3 = peaks_rel_p3 + first_index_above_target_plot3\n",
    "            \n",
    "            if len(peaks_after_threshold_indices_abs_plot3) > num_peaks_skip_start:\n",
    "                start_peak_abs_idx_p3 = peaks_after_threshold_indices_abs_plot3[num_peaks_skip_start]\n",
    "                plot3_start_t = time_signal[start_peak_abs_idx_p3]\n",
    "                # Plot skipped peaks\n",
    "                for k_skip in range(num_peaks_skip_start):\n",
    "                    if k_skip < len(peaks_after_threshold_indices_abs_plot3):\n",
    "                         idx = peaks_after_threshold_indices_abs_plot3[k_skip]\n",
    "                         plt.plot(time_signal[idx], detrended_filtered_signal[idx], 'x', color='silver', ms=6, label='Skipped Start Peak' if k_skip==0 else None)\n",
    "            else: # Not enough peaks to skip\n",
    "                 peaks_after_threshold_indices_abs_plot3 = [] # Clear to indicate failure for this path\n",
    "    \n",
    "    if plot3_start_t == -1: # Fallback start time for plot3\n",
    "        if wave_period_T is not None and isinstance(wave_period_T, (float, int)) and wave_period_T > 0:\n",
    "            plot3_start_t = initial_skip_periods * wave_period_T\n",
    "        else:\n",
    "            plot3_start_t = steady_state_start_time\n",
    "\n",
    "    # Reflection time for current channel (Plot 3)\n",
    "    reflection_time_current_chan_plot3 = np.nan\n",
    "    if wave_period_T and wave_period_T > 0 and channel_name in wave_probe_positions_x:\n",
    "        # ... (reflection calculation as before, assign to reflection_time_current_chan_plot3) ...\n",
    "        k_val_curr = solve_dispersion_for_k(wave_period_T, water_depth, g)\n",
    "        if k_val_curr and not np.isnan(k_val_curr) and k_val_curr > 0:\n",
    "            omega_curr = 2 * np.pi / wave_period_T\n",
    "            C_curr = omega_curr / k_val_curr\n",
    "            n_curr = 0.5 * (1 + (2 * k_val_curr * water_depth) / np.sinh(2 * k_val_curr * water_depth))\n",
    "            Cg_curr = n_curr * C_curr\n",
    "            if Cg_curr > 1e-6:\n",
    "                current_wp_x_pos = wave_probe_positions_x[channel_name]\n",
    "                time_to_reach_curr_probe = current_wp_x_pos / Cg_curr\n",
    "                time_curr_probe_to_wall_and_back = (2 * (L_tank - current_wp_x_pos)) / Cg_curr\n",
    "                if time_curr_probe_to_wall_and_back >= 0:\n",
    "                    reflection_time_current_chan_plot3 = time_to_reach_curr_probe + time_curr_probe_to_wall_and_back\n",
    "                    if not np.isnan(reflection_time_current_chan_plot3): # Add delay if valid\n",
    "                        reflection_time_current_chan_plot3 += reflection_time_delay_sec_plot\n",
    "\n",
    "    # Dynamic End Time for Plot 3\n",
    "    peaks_before_reflection_indices_abs_plot3 = []\n",
    "    if not np.isnan(reflection_time_current_chan_plot3):\n",
    "        idx_refl_p3 = np.searchsorted(time_signal, reflection_time_current_chan_plot3)\n",
    "        if idx_refl_p3 > 0:\n",
    "            min_peak_dist_p3_end = int(fs * wave_period_T * 0.4) if (wave_period_T and wave_period_T > 0 and fs > 0) else int(fs * 0.1)\n",
    "            if min_peak_dist_p3_end < 1: min_peak_dist_p3_end = 1\n",
    "            \n",
    "            peaks_refl_rel_p3, _ = scipy.signal.find_peaks(\n",
    "                detrended_filtered_signal[:idx_refl_p3], \n",
    "                height=min_peak_height_param, distance=min_peak_dist_p3_end)\n",
    "            peaks_before_reflection_indices_abs_plot3 = peaks_refl_rel_p3 # These are already absolute relative to detrended_filtered_signal\n",
    "            \n",
    "            if len(peaks_before_reflection_indices_abs_plot3) > num_peaks_skip_end:\n",
    "                end_peak_abs_idx_p3 = peaks_before_reflection_indices_abs_plot3[-(num_peaks_skip_end + 1)]\n",
    "                plot3_end_t = time_signal[end_peak_abs_idx_p3]\n",
    "                # Plot skipped end peaks\n",
    "                for k_skip in range(num_peaks_skip_end):\n",
    "                    if k_skip < len(peaks_before_reflection_indices_abs_plot3):\n",
    "                        idx = peaks_before_reflection_indices_abs_plot3[-(k_skip + 1)]\n",
    "                        plt.plot(time_signal[idx], detrended_filtered_signal[idx], '+', color='gray', ms=7, label='Skipped End Peak' if k_skip==0 else None)\n",
    "            else: # Not enough peaks to skip\n",
    "                peaks_before_reflection_indices_abs_plot3 = [] # Clear to indicate failure\n",
    "\n",
    "    if plot3_end_t == -1: # Fallback end time for plot3\n",
    "        fallback_end_t_p3 = time_signal[-1]\n",
    "        if not np.isnan(reflection_time_current_chan_plot3):\n",
    "            if wave_period_T is not None and isinstance(wave_period_T, (float, int)) and wave_period_T > 0:\n",
    "                potential_end_t = reflection_time_current_chan_plot3 - (end_buffer_periods * wave_period_T)\n",
    "                fallback_end_t_p3 = min(fallback_end_t_p3, potential_end_t)\n",
    "            else:\n",
    "                fallback_end_t_p3 = min(fallback_end_t_p3, reflection_time_current_chan_plot3)\n",
    "        plot3_end_t = fallback_end_t_p3\n",
    "    \n",
    "    if plot3_end_t <= plot3_start_t:\n",
    "        print(f\"Plot 3 ({channel_name}): Invalid window for visualization. End time {plot3_end_t:.2f}s <= Start time {plot3_start_t:.2f}s.\")\n",
    "        idx_start_plot3, idx_end_plot3 = 0, 0\n",
    "    else:\n",
    "        idx_start_plot3 = np.searchsorted(time_signal, plot3_start_t)\n",
    "        idx_end_plot3 = np.searchsorted(time_signal, plot3_end_t, side='right')\n",
    "\n",
    "    print(f\"Plot 3 ({channel_name}): Visualized analysis window from {plot3_start_t:.2f}s to {plot3_end_t:.2f}s.\")\n",
    "\n",
    "    if idx_start_plot3 < idx_end_plot3 and idx_start_plot3 < len(detrended_filtered_signal):\n",
    "        time_plot3_viz = time_signal[idx_start_plot3:idx_end_plot3]\n",
    "        signal_plot3_viz = detrended_filtered_signal[idx_start_plot3:idx_end_plot3]\n",
    "        if len(signal_plot3_viz) >= 2:\n",
    "            plt.plot(time_plot3_viz, signal_plot3_viz, label=f'Signal for {channel_name} Calc Window', color='green', linewidth=1.5, zorder=2)\n",
    "            \n",
    "            min_dist_p3_final = int(fs * wave_period_T * 0.4) if (wave_period_T and wave_period_T > 0 and fs > 0) else int(fs * 0.1)\n",
    "            if min_dist_p3_final < 1: min_dist_p3_final = 1\n",
    "            peaks_idx_p3_viz, _ = scipy.signal.find_peaks(signal_plot3_viz, height=min_peak_height_param, distance=min_dist_p3_final)\n",
    "\n",
    "            if len(peaks_idx_p3_viz) > 0:\n",
    "                peak_t_p3_viz = time_plot3_viz[peaks_idx_p3_viz]\n",
    "                peak_a_p3_viz = signal_plot3_viz[peaks_idx_p3_viz]\n",
    "                plt.plot(peak_t_p3_viz, peak_a_p3_viz, \"o\", mfc='darkorange', mec='k', ms=7, label=f'Peaks in Calc Window ({len(peak_a_p3_viz)} used)', zorder=3)\n",
    "                avg_p3_viz = np.mean(peak_a_p3_viz)\n",
    "                print(f\"Plot 3: Avg for {channel_name} visualized window ({plot3_start_t:.2f}s to {plot3_end_t:.2f}s): {avg_p3_viz:.6f} m\")\n",
    "            else: print(f\"Plot 3: No peaks in {channel_name} visualized calc window.\")\n",
    "        else: print(f\"Plot 3: {channel_name} visualized calc window signal too short.\")\n",
    "    else: print(f\"Plot 3: {channel_name} visualized calc window invalid or empty.\")\n",
    "\n",
    "    plt.axvline(plot3_start_t, color='dimgray', linestyle='--', label=f'Calc Start ({plot3_start_t:.2f}s)')\n",
    "    if not np.isnan(reflection_time_current_chan_plot3):\n",
    "        plt.axvline(reflection_time_current_chan_plot3, color='magenta', linestyle=':', label=f'{channel_name} Actual Reflect ({reflection_time_current_chan_plot3:.2f}s)')\n",
    "    \n",
    "    # Show calculated end time if it's meaningfully different from reflection or signal end\n",
    "    is_end_meaningful = plot3_end_t < (time_signal[-1] - 0.1) # Not just the end of the signal\n",
    "    if not np.isnan(reflection_time_current_chan_plot3):\n",
    "        is_end_meaningful = is_end_meaningful and not math.isclose(plot3_end_t, reflection_time_current_chan_plot3)\n",
    "    \n",
    "    if is_end_meaningful :\n",
    "        plt.axvline(plot3_end_t, color='darkgreen', linestyle='-.', label=f'Calc End ({plot3_end_t:.2f}s)')\n",
    "\n",
    "    plt.title(f'3. Visualization of `calculate_average_steady_state_amplitude` for {channel_name}')\n",
    "    plt.xlabel('Time (s)')\n",
    "    plt.ylabel('Amplitude (m)')\n",
    "    plt.legend(fontsize='small')\n",
    "    plt.grid(True, linestyle=':', alpha=0.5)\n",
    "    \n",
    "    plt.tight_layout(pad=2.5, h_pad=3.0) # Adjust padding\n",
    "    plt.show()\n",
    "\n",
    "    # Call the main calculation function to compare its output (printed at the end of this test function)\n",
    "    original_avg_amp = calculate_average_steady_state_amplitude(\n",
    "        full_file_path, channel_name, wave_period_T, \n",
    "        steepness_val_from_filename, # New\n",
    "        steady_state_start_time, \n",
    "        filter_order, cutoff_freq_hz,\n",
    "        initial_skip_periods, end_buffer_periods,\n",
    "        target_amplitude_factor_for_start, # Pass new params\n",
    "        num_peaks_skip_start,\n",
    "        num_peaks_skip_end,\n",
    "        reflection_time_delay_sec=reflection_time_delay_sec_plot # Pass delay to calc function\n",
    "    )\n",
    "    print(f\"\\n--- Output from `calculate_average_steady_state_amplitude` for {channel_name} (for comparison) ---\")\n",
    "    print(f\"  Average amplitude: {original_avg_amp:.6f} m\" if original_avg_amp is not None and not np.isnan(original_avg_amp) else \"  Average amplitude: NaN or None\")\n",
    "\n",
    "\n",
    "def plot_amplitude_vs_position_for_tests(df, num_tests_to_plot=5):\n",
    "    \"\"\"\n",
    "    Creates a scatter plot of average amplitude vs. wave probe x-position\n",
    "    for the first few tests, color-coded by test number.\n",
    "\n",
    "    Args:\n",
    "        df (pd.DataFrame): The master DataFrame containing wave probe amplitudes.\n",
    "        num_tests_to_plot (int): The number of initial tests to plot (e.g., 5 for tests 1-5).\n",
    "    \"\"\"\n",
    "    if df.empty:\n",
    "        print(\"DataFrame is empty. Cannot generate scatter plot.\")\n",
    "        return\n",
    "    if 'test_number' not in df.columns:\n",
    "        print(\"Column 'test_number' not found in DataFrame. Cannot generate scatter plot.\")\n",
    "        return\n",
    "\n",
    "    # Ensure test_number is numeric for filtering, coercing errors to NaN and dropping them\n",
    "    df['test_number'] = pd.to_numeric(df['test_number'], errors='coerce')\n",
    "    df_filtered = df.dropna(subset=['test_number'])\n",
    "    df_filtered['test_number'] = df_filtered['test_number'].astype(int)\n",
    "\n",
    "    # Filter for the first num_tests_to_plot tests\n",
    "    tests_to_plot = sorted(df_filtered['test_number'].unique())[:num_tests_to_plot]\n",
    "    \n",
    "    if not tests_to_plot:\n",
    "        print(f\"No tests found within the first {num_tests_to_plot} unique test numbers after filtering.\")\n",
    "        return\n",
    "        \n",
    "    df_subset = df_filtered[df_filtered['test_number'].isin(tests_to_plot)]\n",
    "\n",
    "    if df_subset.empty:\n",
    "        print(f\"No data available for tests {tests_to_plot}. Cannot generate scatter plot.\")\n",
    "        return\n",
    "\n",
    "    plt.figure(figsize=(12, 8))\n",
    "    \n",
    "    # Define colors for the tests\n",
    "    colors = plt.cm.get_cmap('viridis', len(tests_to_plot)) # Using viridis colormap\n",
    "\n",
    "    for i, test_num in enumerate(tests_to_plot):\n",
    "        test_data = df_subset[df_subset['test_number'] == test_num]\n",
    "        if test_data.empty:\n",
    "            continue\n",
    "\n",
    "        x_positions = []\n",
    "        y_amplitudes = []\n",
    "\n",
    "        for wp_name, x_pos in wave_probe_positions_x.items():\n",
    "            amp_col_name = f\"{wp_name}_Avg_Amp\"\n",
    "            if amp_col_name in test_data.columns:\n",
    "                # Assuming one row per file (and thus per test for this filtering)\n",
    "                # If multiple files could have the same test_number, this might need averaging or selection\n",
    "                amplitude = test_data[amp_col_name].values[0] # Get the amplitude for this WP\n",
    "                if not np.isnan(amplitude):\n",
    "                    x_positions.append(x_pos)\n",
    "                    y_amplitudes.append(amplitude)\n",
    "            \n",
    "        if x_positions: # Only plot if there's data for this test\n",
    "            plt.scatter(x_positions, y_amplitudes, color=colors(i), label=f'Test {test_num}', s=50, alpha=0.7)\n",
    "\n",
    "    plt.xlabel('Wave Probe Position (m)')\n",
    "    plt.ylabel('Average Amplitude (m)')\n",
    "    plt.title(f'Amplitude vs. Wave Probe Position (First {len(tests_to_plot)} Tests)')\n",
    "    plt.legend(title=\"Test Number\")\n",
    "    plt.grid(True, linestyle='--', alpha=0.7)\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "def plot_error_ratio_summary(df):\n",
    "    \"\"\"\n",
    "    Creates a scatter plot of the error_ratio (mean_wp_amplitude / inputAmplitude)\n",
    "    vs. test_number.\n",
    "\n",
    "    Args:\n",
    "        df (pd.DataFrame): The master DataFrame, must include 'test_number', \n",
    "                           'inputAmplitude', and 'error_ratio' columns.\n",
    "    \"\"\"\n",
    "    if df.empty:\n",
    "        print(\"DataFrame is empty. Cannot generate error ratio plot.\")\n",
    "        return\n",
    "    \n",
    "    required_cols = ['test_number', 'error_ratio', 'inputAmplitude']\n",
    "    for col in required_cols:\n",
    "        if col not in df.columns:\n",
    "            print(f\"Required column '{col}' not found. Cannot generate error ratio plot.\")\n",
    "            return\n",
    "\n",
    "    df_plot = df.copy()\n",
    "    # Ensure 'test_number' and 'error_ratio' are numeric and drop NaNs for plotting\n",
    "    df_plot['test_number'] = pd.to_numeric(df_plot['test_number'], errors='coerce')\n",
    "    df_plot['error_ratio'] = pd.to_numeric(df_plot['error_ratio'], errors='coerce')\n",
    "    df_plot.dropna(subset=['test_number', 'error_ratio'], inplace=True)\n",
    "\n",
    "    if df_plot.empty:\n",
    "        print(\"No valid data to plot for error ratio summary after NaN removal.\")\n",
    "        return\n",
    "\n",
    "    df_plot.sort_values('test_number', inplace=True)\n",
    "\n",
    "    plt.figure(figsize=(12, 8))\n",
    "    scatter = plt.scatter(df_plot['test_number'], df_plot['error_ratio'], \n",
    "                          c=df_plot['inputAmplitude'], cmap='viridis', s=60, alpha=0.8,\n",
    "                          label='Error Ratio per Test')\n",
    "    \n",
    "    plt.axhline(1.0, color='green', linestyle='--', linewidth=1, label='Ideal Ratio (1.0)')\n",
    "    \n",
    "    cbar = plt.colorbar(scatter, label='Input Amplitude (m)')\n",
    "    plt.xlabel('Test Number')\n",
    "    plt.ylabel('Error Ratio (Mean WP Amplitude / Input Amplitude)')\n",
    "    plt.title('Error Ratio of Measured vs. Input Amplitude (Color-coded by Input Amplitude)')\n",
    "    plt.legend()\n",
    "    plt.grid(True, linestyle=':', alpha=0.6)\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "def plot_all_wps_raw_stacked(full_file_path, vertical_offset_scale=1.0):\n",
    "    \"\"\"\n",
    "    Plots the raw signals for all wave probes (WP3-WP8) from a single file,\n",
    "    stacked vertically on the same subplot for comparison of wave arrival times.\n",
    "\n",
    "    Args:\n",
    "        full_file_path (str): The full path to the .bin data file.\n",
    "        vertical_offset_scale (float): Factor to scale the automatic vertical offset.\n",
    "                                       Increase for more separation, decrease for less.\n",
    "    \"\"\"\n",
    "    print(f\"\\n--- Plotting all WPs raw stacked from {os.path.basename(full_file_path)} ---\")\n",
    "    try:\n",
    "        df = bin_to_dataframe(full_file_path)\n",
    "    except Exception as e:\n",
    "        print(f\"Error loading data for stacked plot: {e}\")\n",
    "        return\n",
    "\n",
    "    if \"Time\" not in df.columns:\n",
    "        print(\"Time column not found in DataFrame for stacked plot.\")\n",
    "        return\n",
    "\n",
    "    time_signal = df[\"Time\"].values\n",
    "    \n",
    "    plt.figure(figsize=(15, 10))\n",
    "    \n",
    "    # Determine a base offset. Use max peak-to-peak of first few seconds of WP3 as a heuristic.\n",
    "    # This is a rough guide; manual adjustment of vertical_offset_scale might be needed.\n",
    "    base_offset = 0.01 # Default small offset\n",
    "    if \"WP3\" in df.columns and len(df[\"WP3\"]) > 100:\n",
    "        initial_signal_wp3 = df[\"WP3\"].values[:min(len(df[\"WP3\"]), int(1000))] # Look at first ~1000 points\n",
    "        if len(initial_signal_wp3) > 1:\n",
    "            ptp = np.ptp(initial_signal_wp3)\n",
    "            if ptp > 1e-5 : # Only use if there's some variation\n",
    "                 base_offset = ptp * vertical_offset_scale\n",
    "    \n",
    "    current_offset = 0\n",
    "    \n",
    "    # Define a consistent order for plotting if desired, e.g., by probe number\n",
    "    wp_channels_to_plot = sorted([wp for wp in wave_probe_positions_x.keys() if wp in df.columns], \n",
    "                                 key=lambda x: int(x[2:])) # Sort by number in WP_X_\n",
    "\n",
    "    for i, channel_name in enumerate(wp_channels_to_plot):\n",
    "        if channel_name in df.columns:\n",
    "            wave_signal = df[channel_name].values\n",
    "            \n",
    "            # Apply offset for stacking\n",
    "            # The first plot is at 0, next is offset, next is 2*offset\n",
    "            # Or, make them descend: 0, -offset, -2*offset\n",
    "            offset_to_apply = -i * base_offset \n",
    "            \n",
    "            plt.plot(time_signal, wave_signal + offset_to_apply, label=f'{channel_name} (offset: {offset_to_apply:.2f}m)')\n",
    "            # Optionally, add a text label next to the start of each trace\n",
    "            if len(time_signal) > 0 and len(wave_signal) > 0:\n",
    "                 plt.text(time_signal[0] - (time_signal[-1]-time_signal[0])*0.05, # Position slightly to the left\n",
    "                          wave_signal[0] + offset_to_apply, \n",
    "                          channel_name, \n",
    "                          verticalalignment='center')\n",
    "        else:\n",
    "            print(f\"Channel {channel_name} not found in data for stacked plot.\")\n",
    "            \n",
    "    plt.title(f'Raw Wave Probe Signals (Stacked) - {os.path.basename(full_file_path)}')\n",
    "    plt.xlabel('Time (s)')\n",
    "    plt.ylabel('Amplitude (m) + Vertical Offset')\n",
    "    # Adjust legend position if plt.text is used for labels, or remove legend if text is sufficient\n",
    "    plt.legend(fontsize='small', loc='upper right') \n",
    "    plt.grid(True, linestyle=':', alpha=0.7)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "# Example usage (optional, can be called from another script or main block)\n",
    "if __name__ == '__main__':\n",
    "    # Ensure the path is correct and files exist there for testing\n",
    "    # wavedocumentation_path = r'C:\\path\\to\\your\\wave_documentation_folder' # Override if needed for direct testing\n",
    "    \n",
    "    # Check if the path exists before trying to create the dataframe\n",
    "    if os.path.exists(wavedocumentation_path) and os.path.isdir(wavedocumentation_path):\n",
    "        print(f\"Attempting to create DataFrame from data in: {wavedocumentation_path}\")\n",
    "        master_df = create_dataframe()\n",
    "        if not master_df.empty:\n",
    "            print(\"\\n--- DataFrame Head (Initial) ---\")\n",
    "            print(master_df.head(2))\n",
    "            \n",
    "            # Calculate mean_wp_amplitude and error_ratio\n",
    "            wp_amp_cols = [f\"{wp_name}_Avg_Amp\" for wp_name in wave_probe_positions_x.keys()]\n",
    "            existing_wp_amp_cols = [col for col in wp_amp_cols if col in master_df.columns]\n",
    "\n",
    "            if existing_wp_amp_cols:\n",
    "                # Ensure WP amplitude columns are numeric before calculating mean\n",
    "                for col in existing_wp_amp_cols:\n",
    "                    master_df[col] = pd.to_numeric(master_df[col], errors='coerce')\n",
    "                \n",
    "                master_df['mean_wp_amplitude'] = master_df[existing_wp_amp_cols].mean(axis=1, skipna=True)\n",
    "                \n",
    "                # Ensure inputAmplitude is numeric\n",
    "                master_df['inputAmplitude'] = pd.to_numeric(master_df['inputAmplitude'], errors='coerce')\n",
    "                \n",
    "                # Calculate error_ratio, handling potential division by zero or NaN inputAmplitude\n",
    "                master_df['error_ratio'] = np.where(\n",
    "                    (master_df['inputAmplitude'].notna()) & (master_df['inputAmplitude'] != 0),\n",
    "                    master_df['mean_wp_amplitude'] / master_df['inputAmplitude'],\n",
    "                    np.nan  # Set to NaN if inputAmplitude is NaN or zero\n",
    "                )\n",
    "                print(\"\\n--- DataFrame Head (with error_ratio) ---\")\n",
    "                print(master_df[['filename', 'inputAmplitude', 'mean_wp_amplitude', 'error_ratio']].head(2))\n",
    "            else:\n",
    "                print(\"No wave probe amplitude columns found to calculate mean_wp_amplitude and error_ratio.\")\n",
    "                master_df['mean_wp_amplitude'] = np.nan\n",
    "                master_df['error_ratio'] = np.nan\n",
    "\n",
    "\n",
    "            # Call the scatter plot function for amplitude vs position\n",
    "            plot_amplitude_vs_position_for_tests(master_df.copy(), num_tests_to_plot=5)\n",
    "\n",
    "            # Call the new error ratio plot function\n",
    "            plot_error_ratio_summary(master_df.copy())\n",
    "\n",
    "         \n",
    "            # files_in_dir = [f for f in os.listdir(wavedocumentation_path) if f.endswith(\".bin\")]\n",
    "            # if files_in_dir:\n",
    "            #     # test_file_name = files_in_dir[0] # Take the first .bin file\n",
    "            #     test_file_name = \"1701-0_8-40(WaveDoc)#1.bin\" # Specific file for testing reflection\n",
    "            #     # test_file_name = \"1701-1_0-40(WaveDoc)#1.bin\" # Another file for variety\n",
    "            #     test_full_path = os.path.join(wavedocumentation_path, test_file_name)\n",
    "                \n",
    "            #     if os.path.exists(test_full_path):\n",
    "            #         try:\n",
    "            #             test_period = extract_variable_from_filename(test_file_name, \"period\")\n",
    "            #             if not isinstance(test_period, (float, int)): test_period = None \n",
    "            #             test_steepness_val = extract_variable_from_filename(test_file_name, \"steepness\")\n",
    "            #             if not isinstance(test_steepness_val, (float, int)): test_steepness_val = None\n",
    "            #         except ValueError:\n",
    "            #             test_period = None \n",
    "            #             test_steepness_val = None\n",
    "                   \n",
    "            #         # --- Test the individual channel plotting function for ALL WPs ---\n",
    "            #         # try:\n",
    "            #         #     temp_df_for_wp_check = bin_to_dataframe(test_full_path)\n",
    "            #         #     available_wps_in_file = [wp for wp in wave_probe_positions_x.keys() if wp in temp_df_for_wp_check.columns]\n",
    "            #         # except Exception as e:\n",
    "            #         #     print(f\"Could not load {test_file_name} to check available WPs: {e}\")\n",
    "            #         #     available_wps_in_file = []\n",
    "\n",
    "            #         # if not available_wps_in_file:\n",
    "            #         #     print(f\"No wave probes found or could be loaded from {test_file_name} for individual plotting.\")\n",
    "            #         # else:\n",
    "            #         #     print(f\"\\nFound WPs in {test_file_name}: {available_wps_in_file}. Generating individual plots...\")\n",
    "\n",
    "            #         # for wp_to_plot in available_wps_in_file:\n",
    "            #         #     print(f\"\\n--- Initiating visual test for {wp_to_plot} in {test_file_name} (Period: {test_period}) ---\")\n",
    "            #         #     test_plot_average_steady_state_amplitude(\n",
    "            #         #         test_full_path, \n",
    "            #         #         wp_to_plot, \n",
    "            #         #         wave_period_T=test_period,\n",
    "            #         #         steepness_val_from_filename=test_steepness_val, \n",
    "            #         #         steady_state_start_time=20.0, \n",
    "            #         #         filter_order=4,\n",
    "            #         #         cutoff_freq_hz=5.0,\n",
    "            #         #         initial_skip_periods=15, \n",
    "            #         #         end_buffer_periods=10,\n",
    "            #         #     )\n",
    "\n",
    "            #         # --- Test the stacked raw plot function (called once for the file) ---\n",
    "            #         # if available_wps_in_file: \n",
    "            #         #     print(f\"\\n--- Initiating stacked raw plot for all WPs in {test_file_name} ---\")\n",
    "            #         #     plot_all_wps_raw_stacked(test_full_path, vertical_offset_scale=1.5) \n",
    "\n",
    "            #     else:\n",
    "            #         print(f\"Test file {test_file_name} not found at {test_full_path}\")\n",
    "            # else:\n",
    "            #     print(\"No .bin files found in the directory to run the visual test.\")\n",
    "\n",
    "        else:\n",
    "            print(\"Resulting DataFrame is empty.\")\n",
    "    else:\n",
    "        print(f\"Error: The specified wavedocumentation_path does not exist or is not a directory: {wavedocumentation_path}\")\n",
    "        print(\"Please ensure the path is correct and contains .bin files.\")\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
